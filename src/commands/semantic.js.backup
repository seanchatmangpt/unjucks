import { defineCommand } from "citty";
import chalk from "chalk";
import fs from 'fs-extra';
import path from 'node:path';
import { SemanticCodeGenerator } from '../lib/semantic-code-generator.js';
import { SemanticQueryEngine } from '../lib/semantic-query-engine.js';
import { SemanticRDFValidator } from '../lib/semantic-rdf-validator.js';
import { SemanticTemplateProcessor } from '../lib/semantic-template-processor.js';
import { RDFDataLoader } from '../lib/rdf-data-loader.js';
import { TurtleParser } from '../lib/turtle-parser.js';

/**
 * Enhanced Semantic Code Generation Engine
 * Generate code from RDF/OWL ontologies with semantic awareness and enterprise features
 */
class SemanticEngine {
  constructor() {
    this.codeGenerator = null;
    this.queryEngine = null;
    this.validator = null;
    this.templateProcessor = null;
    this.dataLoader = null;
    this.parser = null;
    
    // Initialize semantic filters (legacy compatibility)
    this.ontologies = new Map();
    this.templates = new Map();
    this.filters = new Map();
    this.initializeSemanticFilters();
  }

  /**
   * Initialize the semantic engine components
   */
  initialize(options = {}) {
    const baseOptions = {
      enableValidation: true,
      validationLevel: 'standard',
      cacheEnabled: true,
      ...options
    };

    this.codeGenerator = new SemanticCodeGenerator(baseOptions);
    this.queryEngine = new SemanticQueryEngine(baseOptions);
    this.validator = new SemanticRDFValidator(baseOptions);
    this.templateProcessor = new SemanticTemplateProcessor(baseOptions);
    this.dataLoader = new RDFDataLoader(baseOptions);
    this.parser = new TurtleParser(baseOptions.parserOptions);

    return this;
  }

  initializeSemanticFilters() {
    // RDF-aware filters for template processing
    this.filters.set('rdfLabel', (entity) => {
      return entity?.label || entity?.name || 'UnknownEntity';
    });
    
    this.filters.set('rdfType', (entity, type) => {
      return entity?.type === type || entity?.types?.includes(type);
    });
    
    this.filters.set('rdfProperties', (entity) => {
      return entity?.properties || [];
    });
    
    this.filters.set('rdfRequired', (property) => {
      return property?.required || property?.mandatory || false;
    });
    
    this.filters.set('rdfNamespace', (entity, namespace) => {
      return entity?.namespace === namespace;
    });
    
    this.filters.set('pascalCase', (str) => {
      return str?.replace(/(?:^|[-_\s])(\w)/g, (_, c) => c.toUpperCase()).replace(/[-_\s]/g, '');
    });
    
    this.filters.set('camelCase', (str) => {
      const pascal = this.filters.get('pascalCase')(str);
      return pascal ? pascal.charAt(0).toLowerCase() + pascal.slice(1) : '';
    });
  }

  async loadOntology(filePath, format = 'turtle') {
    // Initialize components if not already done
    if (!this.dataLoader) {
      this.initialize();
    }
    
    try {
      // Use RDFDataLoader to load the file
      const ontologyData = await this.dataLoader.loadFromSource({
        type: 'file',
        path: filePath,
        source: filePath
      });
      
      // Parse ontology structure from the loaded data
      const content = await fs.readFile(filePath, 'utf-8');
      const parsedOntology = await this.parseOntology(content, format);
      
      const ontologyId = path.basename(filePath, path.extname(filePath));
      this.ontologies.set(ontologyId, {
        ...parsedOntology,
        ...ontologyData,
        filePath,
        format
      });
      
      return {
        id: ontologyId,
        entities: parsedOntology.entities?.length || 0,
        properties: parsedOntology.properties?.length || 0,
        relationships: parsedOntology.relationships?.length || 0,
        triples: ontologyData.triples?.length || 0
      };
    } catch (error) {
      throw new Error(`Failed to load ontology from ${filePath}: ${error.message}`);
    }
  }

  async parseOntology(content, format) {
    // Use enhanced turtle parser for comprehensive parsing
    if (!this.parser) {
      this.initialize();
    }
    
    const parseResult = await this.parser.parse(content);
    
    // Transform parse result to legacy format for compatibility
    const ontology = {
      entities: parseResult.entities || [],
      properties: parseResult.properties || [],
      relationships: parseResult.relationships || [],
      namespaces: new Map(Object.entries(parseResult.prefixes || {})),
      triples: parseResult.triples || [],
      stats: parseResult.stats || {}
    };
    
    return ontology;
  }

  extractLabel(id) {
    // Extract human-readable label from IRI
    const parts = id.split(/[#\/]/);
    return parts[parts.length - 1] || id;
  }

  async generateSemanticTemplates(ontologyId, options = {}) {
    const ontology = this.ontologies.get(ontologyId);
    if (!ontology) {
      throw new Error(`Ontology not found: ${ontologyId}`);
    }
    
    // Initialize components if not already done
    if (!this.codeGenerator) {
      this.initialize();
    }
    
    // Use enhanced semantic code generator
    const generationConfig = {
      ontology: ontology,
      language: options.language || 'js',
      patterns: options.patterns || ['class', 'interface', 'service'],
      enterprise: options.enterprise || false,
      compliance: options.compliance || [],
      templateDirectory: options.templateDirectory
    };
    
    const result = await this.codeGenerator.generateFromOntology(
      ontologyId, 
      generationConfig,
      options
    );
    
    return {
      ontologyId,
      templates: result.files || [],
      totalTemplates: result.files?.length || 0,
      metadata: result.metadata || {}
    };
  }

  async generateEntityTemplate(entity, ontology, options) {
    const className = this.filters.get('pascalCase')(entity.label);
    const fileName = `${className}.js`;
    
    let content = `// Generated from semantic ontology: ${entity.id}\n`;
    content += `// Entity: ${entity.label}\n`;
    content += `// Type: ${entity.type}\n\n`;
    
    content += `class ${className} {\n`;
    content += `  constructor(data = {}) {\n`;
    content += `    this.id = data.id;\n`;
    
    // Add properties
    entity.properties.forEach(prop => {
      const propName = this.filters.get('camelCase')(this.extractLabel(prop.id));
      content += `    this.${propName} = data.${propName};\n`;
    });
    
    content += `  }\n\n`;
    
    // Add getter methods
    entity.properties.forEach(prop => {
      const propName = this.filters.get('camelCase')(this.extractLabel(prop.id));
      const methodName = this.filters.get('pascalCase')(propName);
      content += `  get${methodName}() {\n`;
      content += `    return this.${propName};\n`;
      content += `  }\n\n`;
      
      content += `  set${methodName}(value) {\n`;
      content += `    this.${propName} = value;\n`;
      content += `  }\n\n`;
    });
    
    // Add semantic methods
    content += `  // Semantic methods\n`;
    content += `  getSemanticType() {\n`;
    content += `    return '${entity.type}';\n`;
    content += `  }\n\n`;
    
    content += `  getSemanticId() {\n`;
    content += `    return '${entity.id}';\n`;
    content += `  }\n\n`;
    
    content += `  toRDF() {\n`;
    content += `    return \`\${this.id} rdf:type ${entity.type} .\`;\n`;
    content += `  }\n`;
    
    content += `}\n\n`;
    content += `module.exports = ${className};\n`;
    
    return {
      entity: entity.id,
      className,
      fileName,
      content,
      size: content.length
    };
  }

  async exportTemplates(templates, outputDir, options = {}) {
    const results = [];
    
    for (const template of templates) {
      const filePath = path.join(outputDir, template.fileName);
      
      if (!options.dry) {
        await fs.ensureDir(outputDir);
        await fs.writeFile(filePath, template.content);
      }
      
      results.push({
        path: filePath,
        size: template.size,
        entity: template.entity,
        className: template.className
      });
    }
    
    return results;
  }

  async validateCompliance(ontologyId, standards = []) {
    const ontology = this.ontologies.get(ontologyId);
    if (!ontology) {
      throw new Error(`Ontology not found: ${ontologyId}`);
    }
    
    // Initialize components if not already done
    if (!this.validator) {
      this.initialize();
    }
    
    // Use enhanced RDF validator for comprehensive compliance checking
    const validationOptions = {
      level: 'enterprise',
      compliance: standards,
      includePerformance: true,
      includeSecurity: true
    };
    
    const result = await this.validator.validateRDF(
      ontology.triples || ontology.content,
      validationOptions
    );
    
    return {
      standards,
      valid: result.isValid,
      errors: result.errors || [],
      warnings: result.warnings || [],
      compliance: result.compliance || {},
      performance: result.performance || {},
      security: result.security || {}
    };
  }

  async validateStandard(ontology, standard) {
    const result = { valid: true, issues: [] };
    
    switch (standard.toLowerCase()) {
      case 'gdpr':
        // Check for personal data handling
        const personalDataEntities = ontology.entities.filter(e => 
          e.label.toLowerCase().includes('person') || 
          e.label.toLowerCase().includes('user') ||
          e.properties.some(p => p.id.includes('email') || p.id.includes('name'))
        );
        
        if (personalDataEntities.length > 0) {
          result.issues.push('Personal data entities found - ensure GDPR compliance measures');
        }
        break;
        
      case 'fhir':
        // Check for FHIR resource compliance
        const fhirResources = ['Patient', 'Practitioner', 'Organization', 'Observation'];
        const hasFhirEntities = ontology.entities.some(e => 
          fhirResources.includes(e.label)
        );
        
        if (!hasFhirEntities) {
          result.issues.push('No FHIR resource entities found');
        }
        break;
        
      case 'basel3':
        // Check for financial risk entities
        const riskEntities = ontology.entities.filter(e =>
          e.label.toLowerCase().includes('risk') ||
          e.label.toLowerCase().includes('capital') ||
          e.label.toLowerCase().includes('liquidity')
        );
        
        if (riskEntities.length === 0) {
          result.issues.push('No risk management entities found for Basel III compliance');
        }
        break;
    }
    
    return result;
  }
}

export const semanticCommand = defineCommand({
  meta: {
    name: "semantic",
    description: "Generate code from RDF/OWL ontologies with semantic awareness",
  },
  args: {
    action: {
      type: "positional",
      description: "Action to perform (generate, validate, convert, analyze)",
      required: false,
    },
    input: {
      type: "string",
      description: "Input ontology file (RDF, Turtle, OWL)",
      alias: "i",
    },
    output: {
      type: "string",
      description: "Output directory for generated code",
      alias: "o",
    },
    format: {
      type: "string",
      description: "Input format (turtle, rdf, owl, jsonld)",
      default: "turtle",
    },
    language: {
      type: "string",
      description: "Target programming language (js, ts, python, java)",
      default: "js",
    },
    compliance: {
      type: "string",
      description: "Compliance standards to validate (gdpr, fhir, basel3)",
    },
    enterprise: {
      type: "boolean",
      description: "Enable enterprise-grade features",
      default: false,
    },
    templates: {
      type: "string",
      description: "Custom template directory",
    },
    dry: {
      type: "boolean",
      description: "Preview mode - don't write files",
      default: false,
    },
    verbose: {
      type: "boolean",
      description: "Enable verbose output",
      alias: "v",
      default: false,
    }
  },
  async run(context) {
    const { args } = context;
    const engine = new SemanticEngine();
    
    console.log(chalk.blue("ðŸ§  Unjucks Semantic Web Engine"));
    console.log(chalk.gray("Generate code from RDF/OWL ontologies with semantic awareness"));
    console.log();
    
    try {
      if (!args.action) {
        // Show help
        console.log(chalk.yellow("ðŸŒ Available Actions:"));
        console.log(chalk.cyan("  generate") + chalk.gray(" - Generate code from ontologies"));
        console.log(chalk.cyan("  validate") + chalk.gray(" - Validate ontology compliance"));
        console.log(chalk.cyan("  convert") + chalk.gray("  - Convert between RDF formats"));
        console.log(chalk.cyan("  analyze") + chalk.gray("  - Analyze ontology structure"));
        console.log();
        console.log(chalk.yellow("ðŸš€ Enterprise Examples:"));
        console.log(chalk.gray('  unjucks semantic generate --input fibo.ttl --output ./generated --compliance basel3'));
        console.log(chalk.gray('  unjucks semantic validate --input healthcare.owl --compliance fhir,gdpr'));
        console.log(chalk.gray('  unjucks semantic convert --input data.ttl --format jsonld'));
        console.log(chalk.gray('  unjucks semantic analyze --input enterprise.owl --enterprise'));
        return;
      }
      
      switch (args.action) {
        case 'generate':
          await handleGenerate(args, engine);
          break;
        case 'validate':
          await handleValidate(args, engine);
          break;
        case 'convert':
          await handleConvert(args, engine);
          break;
        case 'analyze':
          await handleAnalyze(args, engine);
          break;
        default:
          console.log(chalk.red(`âŒ Unknown action: ${args.action}`));
          console.log(chalk.gray('Use: generate, validate, convert, analyze'));
      }
    } catch (error) {
      console.log(chalk.red(`âŒ Error: ${error.message}`));
      if (args.verbose || process.env.DEBUG) {
        console.error(error.stack);
      }
    }
  },
});

// Helper functions for semantic command
async function handleGenerate(args, engine) {
    console.log(chalk.cyan("âš¡ Generating Semantic Code..."));
    
    if (!args.input) {
      console.log(chalk.red("âŒ Input ontology file required (--input)"));
      return;
    }
    
    if (!(await fs.pathExists(args.input))) {
      console.log(chalk.red(`âŒ File not found: ${args.input}`));
      return;
    }
    
    // Initialize engine with advanced options
    engine.initialize({
      enableValidation: true,
      validationLevel: args.enterprise ? 'enterprise' : 'standard',
      cacheEnabled: true
    });
    
    // Load ontology using enhanced data loader
    console.log(chalk.yellow("ðŸ“‚ Loading ontology..."));
    const ontology = await engine.loadOntology(args.input, args.format);
    console.log(chalk.green(`âœ… Loaded ontology: ${ontology.entities} entities, ${ontology.properties} properties, ${ontology.triples} triples`));
    
    // Validate compliance if requested
    if (args.compliance) {
      const standards = args.compliance.split(',').map(s => s.trim());
      console.log(chalk.yellow(`ðŸ”’ Validating compliance: ${standards.join(', ')}`));
      
      const validation = await engine.validateCompliance(ontology.id, standards);
      
      if (validation.valid) {
        console.log(chalk.green("âœ… All compliance validations passed"));
      } else {
        console.log(chalk.yellow("âš ï¸ Compliance issues found:"));
        validation.errors.forEach(error => {
          console.log(chalk.red(`  â€¢ ${error}`));
        });
        validation.warnings.forEach(warning => {
          console.log(chalk.yellow(`  â€¢ ${warning}`));
        });
      }
    }
    
    // Generate templates using enhanced code generator
    console.log(chalk.yellow("ðŸ—ï¸ Generating semantic templates..."));
    const result = await engine.generateSemanticTemplates(ontology.id, {
      language: args.language,
      enterprise: args.enterprise,
      patterns: args.enterprise ? ['class', 'interface', 'service', 'controller', 'repository', 'dto'] : ['class'],
      compliance: args.compliance ? args.compliance.split(',') : [],
      templateDirectory: args.templates
    });
    
    console.log(chalk.green(`âœ… Generated ${result.totalTemplates} semantic templates`));
    
    if (result.metadata) {
      console.log(chalk.gray(`   Patterns: ${Object.keys(result.metadata.patterns || {}).join(', ')}`));
      console.log(chalk.gray(`   Features: ${Object.keys(result.metadata.features || {}).join(', ')}`));
    }
    
    // Export templates
    if (args.output) {
      const exported = await engine.exportTemplates(result.templates, args.output, {
        dry: args.dry,
        overwrite: args.force || false
      });
      
      if (args.dry) {
        console.log(chalk.blue(`ðŸ“‹ Dry run - would export to ${args.output}`));
      } else {
        console.log(chalk.green(`ðŸ’¾ Exported to ${args.output}`));
      }
      
      if (args.verbose) {
        exported.forEach(file => {
          console.log(chalk.gray(`  + ${file.path} (${file.size} bytes)${file.className ? ' - ' + file.className : ''}`));
        });
      }
      
      if (!args.dry) {
        console.log();
        console.log(chalk.blue("ðŸ“ Next steps:"));
        console.log(chalk.gray("  1. Review the generated classes and interfaces"));
        console.log(chalk.gray("  2. Add business logic and validation rules"));
        console.log(chalk.gray("  3. Run tests to validate functionality"));
        console.log(chalk.gray("  4. Consider adding integration with data sources"));
      }
    }
}
  
async function handleValidate(args, engine) {
    console.log(chalk.cyan("âœ… Validating RDF/Turtle Ontology..."));
    
    if (!args.input) {
      console.log(chalk.red("âŒ Input ontology file required (--input)"));
      return;
    }

    try {
      // Import turtle parser for validation
      const { TurtleParser, TurtleParseError } = await import('../lib/turtle-parser.js');
      
      // Read and validate turtle file
      const content = await fs.readFile(args.input, 'utf-8');
      console.log(chalk.gray(`ðŸ“„ File size: ${(content.length / 1024).toFixed(2)} KB`));
      
      // Parse with Turtle parser
      const parser = new TurtleParser({
        baseIRI: args.base || 'http://example.org/',
        format: semanticCommand.mapFormatToN3Format(args.format)
      });
      
      console.log(chalk.cyan("ðŸ” Parsing RDF content..."));
      const parseResult = await parser.parse(content);
      
      console.log(chalk.green("âœ… RDF parsing successful!"));
      console.log();
      
      // Display parse statistics
      console.log(chalk.yellow("ðŸ“Š Parse Statistics:"));
      console.log(chalk.gray(`  Triples: ${parseResult.stats.tripleCount}`));
      console.log(chalk.gray(`  Prefixes: ${parseResult.stats.prefixCount}`));
      console.log(chalk.gray(`  Subjects: ${parseResult.stats.subjectCount}`));
      console.log(chalk.gray(`  Predicates: ${parseResult.stats.predicateCount}`));
      console.log(chalk.gray(`  Parse time: ${parseResult.stats.parseTime}ms`));
      
      if (args.verbose) {
        console.log();
        console.log(chalk.yellow("ðŸ”— Namespace Prefixes:"));
        for (const [prefix, uri] of Object.entries(parseResult.prefixes)) {
          console.log(chalk.gray(`  ${prefix || '(default)'}: ${uri}`));
        }
      }
      
      // Compliance validation if requested
      if (args.compliance) {
        console.log();
        const ontology = await engine.loadOntology(args.input, args.format);
        const standards = args.compliance.split(',');
        const validation = await engine.validateCompliance(ontology.id, standards);
        
        console.log(chalk.yellow("ðŸ“‹ Compliance Report:"));
        
        for (const [standard, result] of Object.entries(validation.compliance)) {
          const status = result.valid ? chalk.green("âœ… PASS") : chalk.red("âŒ FAIL");
          console.log(`  ${standard.toUpperCase()}: ${status}`);
          
          if (result.issues.length > 0) {
            result.issues.forEach(issue => {
              console.log(chalk.gray(`    â€¢ ${issue}`));
            });
          }
        }
        
        if (validation.valid) {
          console.log();
          console.log(chalk.green("ðŸŽ‰ All compliance validations passed"));
        } else {
          console.log();
          console.log(chalk.red("âš ï¸ Some compliance issues found - review and address"));
        }
      }
      
      // Semantic analysis
      console.log();
      console.log(chalk.yellow("ðŸ§  Semantic Analysis:"));
      
      // Analyze common vocabularies
      const vocabularies = semanticCommand.analyzeVocabularies(parseResult.prefixes, parseResult.triples);
      if (vocabularies.length > 0) {
        console.log(chalk.gray(`  Detected vocabularies: ${vocabularies.join(', ')}`));
      } else {
        console.log(chalk.gray(`  No standard vocabularies detected`));
      }
      
      // Basic RDF validation
      const validationIssues = semanticCommand.performBasicRDFValidation(parseResult);
      if (validationIssues.length > 0) {
        console.log();
        console.log(chalk.red("âš ï¸ RDF Validation Issues:"));
        validationIssues.forEach(issue => {
          console.log(chalk.red(`  â€¢ ${issue}`));
        });
      } else {
        console.log(chalk.green(`  âœ… No RDF validation issues found`));
      }
      
    } catch (error) {
      // Check if error has the characteristics of TurtleParseError
      if (error.name === 'TurtleParseError' || error.constructor?.name === 'TurtleParseError') {
        console.log(chalk.red("âŒ RDF Parse Error:"));
        console.log(chalk.red(`  Message: ${error.message}`));
        if (error.line !== undefined) {
          console.log(chalk.red(`  Line: ${error.line}, Column: ${error.column}`));
        }
        if (args.verbose && error.originalError) {
          console.log(chalk.gray(`  Details: ${error.originalError.message}`));
        }
      } else {
        console.log(chalk.red(`âŒ Validation failed: ${error.message}`));
        if (args.verbose) {
          console.error(error.stack);
        }
      }
    }
  },
  
async function handleConvert(args, engine) {
    console.log(chalk.cyan("ðŸ”„ Converting RDF Format..."));
    
    if (!args.input) {
      console.log(chalk.red("âŒ Input file required (--input)"));
      return;
    }
    
    if (!args.output) {
      console.log(chalk.red("âŒ Output file required (--output)"));
      return;
    }
    
    try {
      // Initialize engine with conversion capabilities
      engine.initialize();
      
      console.log(chalk.yellow(`ðŸ“‚ Converting ${args.input} to ${args.output}...`));
      
      // Use template processor for format conversion
      const result = await engine.templateProcessor.convertRDFFormat(args.input, {
        outputPath: args.output,
        inputFormat: args.format,
        outputFormat: path.extname(args.output).slice(1) || 'turtle',
        preserveComments: true
      });
      
      if (result.success) {
        console.log(chalk.green(`âœ… Conversion completed successfully`));
        console.log(chalk.gray(`   Output: ${result.outputPath}`));
        console.log(chalk.gray(`   Size: ${result.outputSize} bytes`));
      } else {
        console.log(chalk.red(`âŒ Conversion failed: ${result.error}`));
      }
      
    } catch (error) {
      console.log(chalk.red(`âŒ Conversion error: ${error.message}`));
      if (args.verbose) {
        console.error(chalk.gray(error.stack));
      }
    }
}
  
async function handleAnalyze(args, engine) {
    console.log(chalk.cyan("ðŸ“Š Analyzing Ontology Structure..."));
    
    if (!args.input) {
      console.log(chalk.red("âŒ Input ontology file required (--input)"));
      return;
    }
    
    const ontology = await engine.loadOntology(args.input, args.format);
    
    console.log();
    console.log(chalk.green("ðŸ“Š Ontology Analysis Report"));
    console.log(chalk.gray(`File: ${args.input}`));
    console.log(chalk.gray(`Format: ${args.format}`));
    console.log();
    
    console.log(chalk.yellow("ðŸ“ˆ Statistics:"));
    console.log(chalk.gray(`  Entities: ${ontology.entities}`));
    console.log(chalk.gray(`  Properties: ${ontology.properties}`));
    console.log(chalk.gray(`  Relationships: ${ontology.relationships}`));
    
    if (args.enterprise) {
      console.log();
      console.log(chalk.yellow("ðŸ¢ Enterprise Features:"));
      console.log(chalk.gray("  â€¢ Scalable architecture analysis"));
      console.log(chalk.gray("  â€¢ Performance optimization suggestions"));
      console.log(chalk.gray("  â€¢ Compliance framework mapping"));
      console.log(chalk.gray("  â€¢ Multi-domain integration patterns"));
    }
  },
  
  mapFormatToN3Format(format) {
    const formatMap = {
      'turtle': 'text/turtle',
      'ttl': 'text/turtle', 
      'nt': 'application/n-triples',
      'ntriples': 'application/n-triples',
      'nq': 'application/n-quads',
      'nquads': 'application/n-quads',
      'n3': 'text/n3',
      'rdf': 'application/rdf+xml',
      'owl': 'application/rdf+xml',
      'jsonld': 'application/ld+json'
    };
    return formatMap[format] || 'text/turtle';
  },
  
  analyzeVocabularies(prefixes, triples) {
    const knownVocabularies = {
      'http://www.w3.org/1999/02/22-rdf-syntax-ns#': 'RDF',
      'http://www.w3.org/2000/01/rdf-schema#': 'RDFS', 
      'http://www.w3.org/2002/07/owl#': 'OWL',
      'http://purl.org/dc/elements/1.1/': 'Dublin Core',
      'http://purl.org/dc/terms/': 'DC Terms',
      'http://xmlns.com/foaf/0.1/': 'FOAF',
      'http://www.w3.org/2004/02/skos/core#': 'SKOS',
      'http://schema.org/': 'Schema.org',
      'http://www.w3.org/ns/prov#': 'PROV'
    };
    
    const detected = new Set();
    
    // Check prefixes
    for (const uri of Object.values(prefixes)) {
      if (knownVocabularies[uri]) {
        detected.add(knownVocabularies[uri]);
      }
    }
    
    // Check triple predicates
    for (const triple of triples.slice(0, 1000)) { // Limit for performance
      for (const [vocabUri, vocabName] of Object.entries(knownVocabularies)) {
        if (triple.predicate.value.startsWith(vocabUri)) {
          detected.add(vocabName);
        }
      }
    }
    
    return Array.from(detected);
  },
  
  performBasicRDFValidation(parseResult) {
    const issues = [];
    
    // Check for suspicious patterns
    let blankSubjects = 0;
    let literalSubjects = 0;
    
    for (const triple of parseResult.triples) {
      if (triple.subject.type === 'blank') {
        blankSubjects++;
      } else if (triple.subject.type === 'literal') {
        literalSubjects++;
        issues.push(`Literal subject found: ${triple.subject.value}`);
      }
    }
    
    if (blankSubjects > parseResult.stats.tripleCount * 0.5) {
      issues.push(`High number of blank nodes (${blankSubjects}/${parseResult.stats.tripleCount}) - may indicate modeling issues`);
    }
    
    // Check for missing type declarations
    const hasTypeDeclarations = parseResult.triples.some(t => 
      t.predicate.value === 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type'
    );
    
    if (!hasTypeDeclarations && parseResult.stats.tripleCount > 10) {
      issues.push('No rdf:type declarations found - consider adding entity types');
    }
    
    return issues;
  }
});