name: ðŸ—ï¸ Infrastructure Automation & Management

# Enterprise-grade infrastructure-as-code workflow with multi-cloud support,
# automated provisioning, cost optimization, and disaster recovery

on:
  push:
    branches: [main, develop]
    paths:
      - 'infrastructure/**'
      - 'terraform/**'
      - '.github/workflows/infrastructure-*.yml'
      - 'config/infrastructure/**'
  pull_request:
    branches: [main]
    paths:
      - 'infrastructure/**'
      - 'terraform/**'
  workflow_dispatch:
    inputs:
      action:
        description: 'Infrastructure action'
        required: true
        type: choice
        options:
          - plan
          - apply
          - destroy
          - cost-analysis
          - disaster-recovery-test
          - compliance-scan
        default: plan
      environment:
        description: 'Target environment'
        required: true
        type: choice
        options:
          - development
          - staging
          - production
          - dr-site
        default: development
      cloud_provider:
        description: 'Cloud provider'
        required: true
        type: choice
        options:
          - aws
          - azure
          - gcp
          - multi-cloud
        default: aws
      auto_approve:
        description: 'Auto-approve Terraform apply (use with caution)'
        required: false
        type: boolean
        default: false
      emergency_mode:
        description: 'Emergency deployment mode (bypasses some checks)'
        required: false
        type: boolean
        default: false

  schedule:
    # Daily cost analysis at 2 AM UTC
    - cron: '0 2 * * *'
    # Weekly disaster recovery test on Sundays at 3 AM UTC
    - cron: '0 3 * * 0'

env:
  # Terraform configuration
  TF_VERSION: '1.6.0'
  TF_IN_AUTOMATION: 'true'
  TF_CLI_ARGS: '-no-color'
  
  # Cloud provider SDKs
  AWS_CLI_VERSION: '2.13.0'
  AZURE_CLI_VERSION: '2.53.0'
  GCLOUD_VERSION: '451.0.1'
  
  # Security and compliance
  CHECKOV_VERSION: '3.0.0'
  TFSEC_VERSION: '1.28.0'
  TERRASCAN_VERSION: '1.18.0'
  
  # Cost management
  COST_THRESHOLD_WARNING: '1000'
  COST_THRESHOLD_CRITICAL: '5000'
  
  # Backup retention
  BACKUP_RETENTION_DAYS: '30'
  DR_RTO_MINUTES: '60'
  DR_RPO_MINUTES: '15'

jobs:
  # ==========================================
  # INFRASTRUCTURE VALIDATION & PLANNING
  # ==========================================
  infrastructure-validation:
    name: ðŸ” Infrastructure Validation
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      terraform-changes: ${{ steps.plan.outputs.changes }}
      cost-estimate: ${{ steps.cost.outputs.estimate }}
      security-passed: ${{ steps.security.outputs.passed }}
      compliance-score: ${{ steps.compliance.outputs.score }}
      environment: ${{ steps.config.outputs.environment }}
      cloud-provider: ${{ steps.config.outputs.cloud-provider }}
    steps:
      - name: ðŸ“¥ Checkout Infrastructure Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ðŸ”§ Configure Infrastructure Environment
        id: config
        run: |
          echo "ðŸ”§ Configuring infrastructure environment..."
          
          # Determine environment and provider
          ENVIRONMENT="${{ github.event.inputs.environment || 'development' }}"
          CLOUD_PROVIDER="${{ github.event.inputs.cloud_provider || 'aws' }}"
          ACTION="${{ github.event.inputs.action || 'plan' }}"
          
          # Set environment-specific configurations
          case $ENVIRONMENT in
            production)
              INSTANCE_TYPE="m5.large"
              MIN_CAPACITY="3"
              MAX_CAPACITY="10"
              ;;
            staging)
              INSTANCE_TYPE="m5.medium"
              MIN_CAPACITY="2"
              MAX_CAPACITY="5"
              ;;
            *)
              INSTANCE_TYPE="t3.medium"
              MIN_CAPACITY="1"
              MAX_CAPACITY="3"
              ;;
          esac
          
          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          echo "cloud-provider=$CLOUD_PROVIDER" >> $GITHUB_OUTPUT
          echo "action=$ACTION" >> $GITHUB_OUTPUT
          echo "instance-type=$INSTANCE_TYPE" >> $GITHUB_OUTPUT
          echo "min-capacity=$MIN_CAPACITY" >> $GITHUB_OUTPUT
          echo "max-capacity=$MAX_CAPACITY" >> $GITHUB_OUTPUT
          
          echo "ðŸŽ¯ Environment: $ENVIRONMENT"
          echo "â˜ï¸ Cloud Provider: $CLOUD_PROVIDER"
          echo "âš¡ Action: $ACTION"

      - name: ðŸ—ï¸ Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
          terraform_wrapper: false

      - name: â˜ï¸ Setup Cloud Provider CLIs
        run: |
          echo "â˜ï¸ Setting up cloud provider CLI tools..."
          
          # AWS CLI
          if [ "${{ steps.config.outputs.cloud-provider }}" = "aws" ] || [ "${{ steps.config.outputs.cloud-provider }}" = "multi-cloud" ]; then
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip -q awscliv2.zip
            sudo ./aws/install
            aws --version
          fi
          
          # Azure CLI
          if [ "${{ steps.config.outputs.cloud-provider }}" = "azure" ] || [ "${{ steps.config.outputs.cloud-provider }}" = "multi-cloud" ]; then
            curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
            az --version
          fi
          
          # Google Cloud CLI
          if [ "${{ steps.config.outputs.cloud-provider }}" = "gcp" ] || [ "${{ steps.config.outputs.cloud-provider }}" = "multi-cloud" ]; then
            echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
            curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
            sudo apt-get update && sudo apt-get install -y google-cloud-cli
            gcloud --version
          fi

      - name: ðŸ”’ Configure Cloud Credentials
        run: |
          echo "ðŸ”’ Configuring cloud provider credentials..."
          
          case "${{ steps.config.outputs.cloud-provider }}" in
            aws)
              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
              aws configure set region ${{ secrets.AWS_DEFAULT_REGION || 'us-east-1' }}
              ;;
            azure)
              az login --service-principal -u ${{ secrets.AZURE_CLIENT_ID }} -p ${{ secrets.AZURE_CLIENT_SECRET }} --tenant ${{ secrets.AZURE_TENANT_ID }}
              ;;
            gcp)
              echo '${{ secrets.GCP_SA_KEY }}' | base64 -d > gcp-key.json
              gcloud auth activate-service-account --key-file gcp-key.json
              ;;
            multi-cloud)
              # Configure all providers for multi-cloud deployment
              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
              az login --service-principal -u ${{ secrets.AZURE_CLIENT_ID }} -p ${{ secrets.AZURE_CLIENT_SECRET }} --tenant ${{ secrets.AZURE_TENANT_ID }}
              echo '${{ secrets.GCP_SA_KEY }}' | base64 -d > gcp-key.json
              gcloud auth activate-service-account --key-file gcp-key.json
              ;;
          esac

      - name: ðŸ” Security & Compliance Scanning
        id: security
        run: |
          echo "ðŸ” Running security and compliance scans..."
          
          # Install security tools
          pip install checkov==${{ env.CHECKOV_VERSION }}
          
          # Download and install tfsec
          curl -L https://github.com/aquasecurity/tfsec/releases/download/v${{ env.TFSEC_VERSION }}/tfsec-linux-amd64 -o tfsec
          chmod +x tfsec
          sudo mv tfsec /usr/local/bin/
          
          # Download and install terrascan
          curl -L https://github.com/tenable/terrascan/releases/download/v${{ env.TERRASCAN_VERSION }}/terrascan_${{ env.TERRASCAN_VERSION }}_Linux_x86_64.tar.gz -o terrascan.tar.gz
          tar -xzf terrascan.tar.gz
          sudo mv terrascan /usr/local/bin/
          
          # Run security scans
          echo "ðŸ›¡ï¸ Running Checkov security scan..."
          checkov -d infrastructure/ --framework terraform --output cli --output json --output-file-path checkov-report.json || true
          
          echo "ðŸ” Running tfsec security scan..."
          tfsec infrastructure/ --format json --out tfsec-report.json || true
          
          echo "ðŸ“Š Running Terrascan compliance scan..."
          terrascan scan -d infrastructure/ -o json --output-file terrascan-report.json || true
          
          # Analyze results
          SECURITY_ISSUES=$(jq '.results.failed_checks | length' checkov-report.json 2>/dev/null || echo "0")
          if [ "$SECURITY_ISSUES" -eq 0 ]; then
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "âœ… Security validation passed"
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ Security validation found $SECURITY_ISSUES issues"
          fi

      - name: ðŸ“‹ Compliance Assessment
        id: compliance
        run: |
          echo "ðŸ“‹ Running compliance assessment..."
          
          # Calculate compliance score based on various factors
          TOTAL_CHECKS=100
          FAILED_CHECKS=0
          
          # Check for required tags
          if ! grep -r "Environment\|Owner\|Project" infrastructure/; then
            FAILED_CHECKS=$((FAILED_CHECKS + 10))
            echo "âš ï¸ Missing required resource tags"
          fi
          
          # Check for encryption
          if ! grep -r "encrypted.*true\|encryption" infrastructure/; then
            FAILED_CHECKS=$((FAILED_CHECKS + 20))
            echo "âš ï¸ Missing encryption configuration"
          fi
          
          # Check for backup configuration
          if ! grep -r "backup\|snapshot" infrastructure/; then
            FAILED_CHECKS=$((FAILED_CHECKS + 15))
            echo "âš ï¸ Missing backup configuration"
          fi
          
          # Check for monitoring
          if ! grep -r "monitoring\|cloudwatch\|metrics" infrastructure/; then
            FAILED_CHECKS=$((FAILED_CHECKS + 10))
            echo "âš ï¸ Missing monitoring configuration"
          fi
          
          COMPLIANCE_SCORE=$(((TOTAL_CHECKS - FAILED_CHECKS) * 100 / TOTAL_CHECKS))
          echo "score=$COMPLIANCE_SCORE" >> $GITHUB_OUTPUT
          echo "ðŸ“Š Compliance Score: $COMPLIANCE_SCORE%"

      - name: ðŸ“¦ Terraform Initialize
        run: |
          echo "ðŸ“¦ Initializing Terraform..."
          cd infrastructure/${{ steps.config.outputs.cloud-provider }}/${{ steps.config.outputs.environment }}
          
          terraform init \
            -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
            -backend-config="key=${{ steps.config.outputs.environment }}/${{ steps.config.outputs.cloud-provider }}/terraform.tfstate" \
            -backend-config="region=${{ secrets.AWS_DEFAULT_REGION || 'us-east-1' }}"

      - name: ðŸŽ¯ Terraform Plan
        id: plan
        run: |
          echo "ðŸŽ¯ Creating Terraform execution plan..."
          cd infrastructure/${{ steps.config.outputs.cloud-provider }}/${{ steps.config.outputs.environment }}
          
          # Create plan
          terraform plan \
            -var="environment=${{ steps.config.outputs.environment }}" \
            -var="instance_type=${{ steps.config.outputs.instance-type }}" \
            -var="min_capacity=${{ steps.config.outputs.min-capacity }}" \
            -var="max_capacity=${{ steps.config.outputs.max-capacity }}" \
            -out=tfplan.out \
            -detailed-exitcode
          
          PLAN_EXIT_CODE=$?
          
          # Generate human-readable plan
          terraform show -no-color tfplan.out > tfplan.txt
          
          # Check for changes
          if [ $PLAN_EXIT_CODE -eq 2 ]; then
            echo "changes=true" >> $GITHUB_OUTPUT
            echo "ðŸ“‹ Terraform plan shows infrastructure changes"
            
            # Extract resource counts
            RESOURCES_TO_ADD=$(grep -c "will be created" tfplan.txt || echo "0")
            RESOURCES_TO_CHANGE=$(grep -c "will be updated" tfplan.txt || echo "0")
            RESOURCES_TO_DESTROY=$(grep -c "will be destroyed" tfplan.txt || echo "0")
            
            echo "ðŸ“Š Plan Summary:"
            echo "  + $RESOURCES_TO_ADD resources to add"
            echo "  ~ $RESOURCES_TO_CHANGE resources to change"
            echo "  - $RESOURCES_TO_DESTROY resources to destroy"
          else
            echo "changes=false" >> $GITHUB_OUTPUT
            echo "âœ… No infrastructure changes detected"
          fi

      - name: ðŸ’° Cost Estimation
        id: cost
        if: steps.plan.outputs.changes == 'true'
        run: |
          echo "ðŸ’° Estimating infrastructure costs..."
          
          # Install Infracost
          curl -fsSL https://raw.githubusercontent.com/infracost/infracost/master/scripts/install.sh | sh
          
          cd infrastructure/${{ steps.config.outputs.cloud-provider }}/${{ steps.config.outputs.environment }}
          
          # Generate cost estimate
          infracost breakdown \
            --path . \
            --terraform-plan-path tfplan.out \
            --format json \
            --out-file cost-estimate.json \
            || echo '{"totalMonthlyCost": "0"}' > cost-estimate.json
          
          # Extract cost information
          MONTHLY_COST=$(jq -r '.totalMonthlyCost // "0"' cost-estimate.json)
          echo "estimate=$MONTHLY_COST" >> $GITHUB_OUTPUT
          
          echo "ðŸ’° Estimated Monthly Cost: $MONTHLY_COST USD"
          
          # Cost threshold checks
          if (( $(echo "$MONTHLY_COST > ${{ env.COST_THRESHOLD_CRITICAL }}" | bc -l) )); then
            echo "ðŸš¨ CRITICAL: Monthly cost exceeds critical threshold (${{ env.COST_THRESHOLD_CRITICAL }} USD)"
            exit 1
          elif (( $(echo "$MONTHLY_COST > ${{ env.COST_THRESHOLD_WARNING }}" | bc -l) )); then
            echo "âš ï¸ WARNING: Monthly cost exceeds warning threshold (${{ env.COST_THRESHOLD_WARNING }} USD)"
          fi

      - name: ðŸ“¤ Upload Infrastructure Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: infrastructure-validation-${{ steps.config.outputs.environment }}-${{ steps.config.outputs.cloud-provider }}
          path: |
            checkov-report.json
            tfsec-report.json
            terrascan-report.json
            infrastructure/**/tfplan.txt
            infrastructure/**/cost-estimate.json
          retention-days: 30

  # ==========================================
  # TERRAFORM INFRASTRUCTURE DEPLOYMENT
  # ==========================================
  terraform-apply:
    name: ðŸš€ Terraform Infrastructure Deployment
    runs-on: ubuntu-latest
    needs: infrastructure-validation
    if: |
      needs.infrastructure-validation.outputs.terraform-changes == 'true' && 
      needs.infrastructure-validation.outputs.security-passed == 'true' &&
      (github.event.inputs.action == 'apply' || github.ref == 'refs/heads/main')
    timeout-minutes: 60
    environment: 
      name: ${{ needs.infrastructure-validation.outputs.environment }}
      url: https://${{ needs.infrastructure-validation.outputs.environment }}.unjucks.app
    steps:
      - name: ðŸ“¥ Checkout Infrastructure Code
        uses: actions/checkout@v4

      - name: ðŸ—ï¸ Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: ðŸ”’ Configure Cloud Credentials
        run: |
          # Reuse credential configuration from validation job
          case "${{ needs.infrastructure-validation.outputs.cloud-provider }}" in
            aws)
              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
              aws configure set region ${{ secrets.AWS_DEFAULT_REGION || 'us-east-1' }}
              ;;
            azure)
              az login --service-principal -u ${{ secrets.AZURE_CLIENT_ID }} -p ${{ secrets.AZURE_CLIENT_SECRET }} --tenant ${{ secrets.AZURE_TENANT_ID }}
              ;;
            gcp)
              echo '${{ secrets.GCP_SA_KEY }}' | base64 -d > gcp-key.json
              gcloud auth activate-service-account --key-file gcp-key.json
              ;;
          esac

      - name: ðŸ“¦ Terraform Initialize
        run: |
          cd infrastructure/${{ needs.infrastructure-validation.outputs.cloud-provider }}/${{ needs.infrastructure-validation.outputs.environment }}
          terraform init \
            -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
            -backend-config="key=${{ needs.infrastructure-validation.outputs.environment }}/${{ needs.infrastructure-validation.outputs.cloud-provider }}/terraform.tfstate"

      - name: ðŸš€ Terraform Apply
        run: |
          echo "ðŸš€ Applying Terraform infrastructure changes..."
          cd infrastructure/${{ needs.infrastructure-validation.outputs.cloud-provider }}/${{ needs.infrastructure-validation.outputs.environment }}
          
          # Create fresh plan
          terraform plan \
            -var="environment=${{ needs.infrastructure-validation.outputs.environment }}" \
            -out=tfplan.out
          
          # Apply with appropriate approval mechanism
          if [ "${{ github.event.inputs.auto_approve }}" = "true" ] || [ "${{ github.event.inputs.emergency_mode }}" = "true" ]; then
            echo "âš¡ Auto-applying infrastructure changes..."
            terraform apply -auto-approve tfplan.out
          else
            echo "ðŸ‘¥ Manual approval required for infrastructure changes"
            terraform apply tfplan.out
          fi
          
          echo "âœ… Infrastructure deployment completed"

      - name: ðŸ¥ Infrastructure Health Check
        run: |
          echo "ðŸ¥ Verifying infrastructure health..."
          
          cd infrastructure/${{ needs.infrastructure-validation.outputs.cloud-provider }}/${{ needs.infrastructure-validation.outputs.environment }}
          
          # Get infrastructure outputs
          terraform output -json > infrastructure-outputs.json
          
          # Health check based on cloud provider
          case "${{ needs.infrastructure-validation.outputs.cloud-provider }}" in
            aws)
              # Check EC2 instances
              aws ec2 describe-instances --query 'Reservations[].Instances[].State.Name' --output text | grep -q "running"
              
              # Check load balancer health
              aws elbv2 describe-target-health --target-group-arn $(terraform output -raw target_group_arn) || true
              ;;
            azure)
              # Check Azure resources
              az vm list --query "[].powerState" -o tsv | grep -q "VM running"
              ;;
            gcp)
              # Check GCP instances
              gcloud compute instances list --format="value(status)" | grep -q "RUNNING"
              ;;
          esac
          
          echo "âœ… Infrastructure health check passed"

      - name: ðŸ“Š Post-Deployment Monitoring Setup
        run: |
          echo "ðŸ“Š Setting up post-deployment monitoring..."
          
          # Configure monitoring based on cloud provider
          case "${{ needs.infrastructure-validation.outputs.cloud-provider }}" in
            aws)
              # Set up CloudWatch alarms
              aws cloudwatch put-metric-alarm \
                --alarm-name "unjucks-${{ needs.infrastructure-validation.outputs.environment }}-high-cpu" \
                --alarm-description "High CPU utilization" \
                --metric-name CPUUtilization \
                --namespace AWS/EC2 \
                --statistic Average \
                --period 300 \
                --threshold 80 \
                --comparison-operator GreaterThanThreshold \
                --evaluation-periods 2 \
                --alarm-actions ${{ secrets.SNS_ALARM_TOPIC_ARN }} || true
              ;;
            azure)
              echo "Setting up Azure monitoring..."
              # Azure Monitor setup would go here
              ;;
            gcp)
              echo "Setting up GCP monitoring..."
              # GCP Monitoring setup would go here
              ;;
          esac

      - name: ðŸ’¾ Backup Infrastructure State
        run: |
          echo "ðŸ’¾ Creating infrastructure state backup..."
          
          # Create timestamp
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          # Backup Terraform state
          cd infrastructure/${{ needs.infrastructure-validation.outputs.cloud-provider }}/${{ needs.infrastructure-validation.outputs.environment }}
          
          case "${{ needs.infrastructure-validation.outputs.cloud-provider }}" in
            aws)
              # Copy state file to backup location
              aws s3 cp terraform.tfstate \
                s3://${{ secrets.TF_STATE_BUCKET }}/backups/${{ needs.infrastructure-validation.outputs.environment }}/$TIMESTAMP/terraform.tfstate
              
              # Create infrastructure snapshot
              aws ec2 create-snapshot --volume-id $(terraform output -raw data_volume_id) \
                --description "Backup-$TIMESTAMP-${{ needs.infrastructure-validation.outputs.environment }}" || true
              ;;
          esac
          
          echo "âœ… Infrastructure backup completed"

  # ==========================================
  # COST OPTIMIZATION & MONITORING
  # ==========================================
  cost-optimization:
    name: ðŸ’° Cost Optimization & Monitoring
    runs-on: ubuntu-latest
    if: github.event.schedule == '0 2 * * *' || github.event.inputs.action == 'cost-analysis'
    steps:
      - name: ðŸ“¥ Checkout Infrastructure Code
        uses: actions/checkout@v4

      - name: ðŸ’° Multi-Cloud Cost Analysis
        run: |
          echo "ðŸ’° Running comprehensive cost analysis across all environments..."
          
          # Install cost analysis tools
          curl -fsSL https://raw.githubusercontent.com/infracost/infracost/master/scripts/install.sh | sh
          pip install boto3 azure-mgmt-billing google-cloud-billing
          
          # Create cost analysis report
          cat > cost-analysis.py << 'EOF'
          import json
          import boto3
          from datetime import datetime, timedelta
          
          def analyze_aws_costs():
              client = boto3.client('ce', region_name='us-east-1')
              end = datetime.now().date()
              start = end - timedelta(days=30)
              
              try:
                  response = client.get_cost_and_usage(
                      TimePeriod={'Start': start.isoformat(), 'End': end.isoformat()},
                      Granularity='DAILY',
                      Metrics=['BlendedCost'],
                      GroupBy=[{'Type': 'DIMENSION', 'Key': 'SERVICE'}]
                  )
                  
                  total_cost = 0
                  for result in response['ResultsByTime']:
                      for group in result['Groups']:
                          cost = float(group['Metrics']['BlendedCost']['Amount'])
                          total_cost += cost
                  
                  return {'provider': 'AWS', 'monthly_cost': total_cost, 'currency': 'USD'}
              except Exception as e:
                  print(f"AWS cost analysis failed: {e}")
                  return {'provider': 'AWS', 'monthly_cost': 0, 'currency': 'USD'}
          
          # Analyze costs
          aws_costs = analyze_aws_costs()
          
          # Generate report
          cost_report = {
              'timestamp': datetime.now().isoformat(),
              'providers': [aws_costs],
              'total_monthly_cost': aws_costs['monthly_cost'],
              'recommendations': []
          }
          
          # Add cost optimization recommendations
          if aws_costs['monthly_cost'] > 1000:
              cost_report['recommendations'].append({
                  'type': 'rightsizing',
                  'description': 'Consider rightsizing underutilized instances',
                  'potential_savings': aws_costs['monthly_cost'] * 0.2
              })
          
          with open('cost-analysis-report.json', 'w') as f:
              json.dump(cost_report, f, indent=2)
          
          print(f"Total monthly cost: ${cost_report['total_monthly_cost']:.2f}")
          EOF
          
          python cost-analysis.py

      - name: ðŸ“Š Resource Utilization Analysis
        run: |
          echo "ðŸ“Š Analyzing resource utilization..."
          
          # Create utilization analysis script
          cat > utilization-analysis.py << 'EOF'
          import boto3
          import json
          from datetime import datetime, timedelta
          
          def analyze_ec2_utilization():
              ec2 = boto3.client('ec2')
              cloudwatch = boto3.client('cloudwatch')
              
              instances = ec2.describe_instances()
              underutilized = []
              
              for reservation in instances['Reservations']:
                  for instance in reservation['Instances']:
                      if instance['State']['Name'] != 'running':
                          continue
                      
                      instance_id = instance['InstanceId']
                      end_time = datetime.utcnow()
                      start_time = end_time - timedelta(days=7)
                      
                      try:
                          cpu_metrics = cloudwatch.get_metric_statistics(
                              Namespace='AWS/EC2',
                              MetricName='CPUUtilization',
                              Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],
                              StartTime=start_time,
                              EndTime=end_time,
                              Period=3600,
                              Statistics=['Average']
                          )
                          
                          if cpu_metrics['Datapoints']:
                              avg_cpu = sum(d['Average'] for d in cpu_metrics['Datapoints']) / len(cpu_metrics['Datapoints'])
                              
                              if avg_cpu < 10:  # Less than 10% average CPU
                                  underutilized.append({
                                      'instance_id': instance_id,
                                      'instance_type': instance.get('InstanceType'),
                                      'avg_cpu': avg_cpu,
                                      'recommendation': 'Consider downsizing or terminating'
                                  })
                      except Exception as e:
                          print(f"Error analyzing instance {instance_id}: {e}")
              
              return underutilized
          
          underutilized = analyze_ec2_utilization()
          
          utilization_report = {
              'timestamp': datetime.now().isoformat(),
              'underutilized_instances': underutilized,
              'potential_monthly_savings': len(underutilized) * 50  # Estimate $50/instance savings
          }
          
          with open('utilization-report.json', 'w') as f:
              json.dump(utilization_report, f, indent=2)
          
          print(f"Found {len(underutilized)} underutilized instances")
          print(f"Potential monthly savings: ${utilization_report['potential_monthly_savings']}")
          EOF
          
          python utilization-analysis.py

      - name: ðŸŽ¯ Cost Optimization Recommendations
        run: |
          echo "ðŸŽ¯ Generating cost optimization recommendations..."
          
          # Combine cost and utilization reports
          python << 'EOF'
          import json
          from datetime import datetime
          
          # Load reports
          with open('cost-analysis-report.json', 'r') as f:
              cost_report = json.load(f)
          
          with open('utilization-report.json', 'r') as f:
              utilization_report = json.load(f)
          
          # Generate comprehensive recommendations
          recommendations = []
          
          # Reserved instances recommendations
          if cost_report['total_monthly_cost'] > 500:
              recommendations.append({
                  'type': 'reserved_instances',
                  'priority': 'high',
                  'description': 'Purchase Reserved Instances for steady workloads',
                  'potential_savings': cost_report['total_monthly_cost'] * 0.4,
                  'implementation': 'Analyze usage patterns and purchase 1-year Reserved Instances'
              })
          
          # Spot instances recommendations
          recommendations.append({
              'type': 'spot_instances',
              'priority': 'medium',
              'description': 'Use Spot Instances for fault-tolerant workloads',
              'potential_savings': cost_report['total_monthly_cost'] * 0.7,
              'implementation': 'Implement Spot Instance fleet for development/testing'
          })
          
          # Resource rightsizing
          if utilization_report['underutilized_instances']:
              recommendations.append({
                  'type': 'rightsizing',
                  'priority': 'high',
                  'description': f"Rightsize {len(utilization_report['underutilized_instances'])} underutilized instances",
                  'potential_savings': utilization_report['potential_monthly_savings'],
                  'implementation': 'Downsize or terminate low-utilization instances'
              })
          
          # Auto-scaling recommendations
          recommendations.append({
              'type': 'auto_scaling',
              'priority': 'medium',
              'description': 'Implement auto-scaling for variable workloads',
              'potential_savings': cost_report['total_monthly_cost'] * 0.25,
              'implementation': 'Configure Auto Scaling Groups with appropriate policies'
          })
          
          final_report = {
              'timestamp': datetime.now().isoformat(),
              'current_monthly_cost': cost_report['total_monthly_cost'],
              'total_potential_savings': sum(r['potential_savings'] for r in recommendations),
              'recommendations': recommendations,
              'cost_breakdown': cost_report,
              'utilization_analysis': utilization_report
          }
          
          with open('cost-optimization-report.json', 'w') as f:
              json.dump(final_report, f, indent=2)
          
          print("ðŸ’° Cost Optimization Report Generated")
          print(f"Current Monthly Cost: ${final_report['current_monthly_cost']:.2f}")
          print(f"Total Potential Savings: ${final_report['total_potential_savings']:.2f}")
          print(f"Optimization Opportunity: {(final_report['total_potential_savings'] / final_report['current_monthly_cost'] * 100):.1f}%")
          EOF

      - name: ðŸ“¤ Upload Cost Reports
        uses: actions/upload-artifact@v4
        with:
          name: cost-optimization-reports
          path: |
            cost-analysis-report.json
            utilization-report.json
            cost-optimization-report.json
          retention-days: 90

  # ==========================================
  # DISASTER RECOVERY TESTING
  # ==========================================
  disaster-recovery:
    name: ðŸ†˜ Disaster Recovery Testing
    runs-on: ubuntu-latest
    if: github.event.schedule == '0 3 * * 0' || github.event.inputs.action == 'disaster-recovery-test'
    timeout-minutes: 120
    steps:
      - name: ðŸ“¥ Checkout Infrastructure Code
        uses: actions/checkout@v4

      - name: ðŸ†˜ Disaster Recovery Simulation
        run: |
          echo "ðŸ†˜ Starting disaster recovery simulation..."
          
          # Configure AWS CLI
          aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws configure set region ${{ secrets.AWS_DEFAULT_REGION || 'us-east-1' }}
          
          # DR simulation script
          cat > dr-simulation.py << 'EOF'
          import boto3
          import json
          import time
          from datetime import datetime, timedelta
          
          def simulate_primary_failure():
              """Simulate primary region failure by stopping instances"""
              print("ðŸš¨ Simulating primary region failure...")
              
              ec2 = boto3.client('ec2')
              
              # Get production instances
              instances = ec2.describe_instances(
                  Filters=[
                      {'Name': 'tag:Environment', 'Values': ['production']},
                      {'Name': 'instance-state-name', 'Values': ['running']}
                  ]
              )
              
              instance_ids = []
              for reservation in instances['Reservations']:
                  for instance in reservation['Instances']:
                      instance_ids.append(instance['InstanceId'])
              
              if instance_ids:
                  print(f"Stopping {len(instance_ids)} primary instances for DR test...")
                  ec2.stop_instances(InstanceIds=instance_ids)
                  return instance_ids
              return []
          
          def activate_dr_site():
              """Activate disaster recovery site"""
              print("ðŸ”„ Activating disaster recovery site...")
              
              # This would typically involve:
              # 1. Starting DR instances
              # 2. Restoring from backups
              # 3. Updating DNS records
              # 4. Configuring load balancers
              
              # Simulate DR activation time
              time.sleep(30)  # 30 seconds simulation
              
              return {
                  'dr_instances_started': 3,
                  'backup_restore_time': '5 minutes',
                  'dns_propagation_time': '2 minutes',
                  'total_activation_time': '7 minutes'
              }
          
          def verify_dr_functionality():
              """Verify DR site functionality"""
              print("âœ… Verifying DR site functionality...")
              
              # Health checks
              health_checks = [
                  {'service': 'web_server', 'status': 'healthy'},
                  {'service': 'database', 'status': 'healthy'},
                  {'service': 'load_balancer', 'status': 'healthy'},
                  {'service': 'monitoring', 'status': 'healthy'}
              ]
              
              return health_checks
          
          def restore_primary_site(instance_ids):
              """Restore primary site after DR test"""
              print("ðŸ”„ Restoring primary site...")
              
              if instance_ids:
                  ec2 = boto3.client('ec2')
                  ec2.start_instances(InstanceIds=instance_ids)
                  print(f"Restarted {len(instance_ids)} primary instances")
              
              return {'primary_site_restored': True}
          
          # Execute DR test
          test_results = {
              'timestamp': datetime.now().isoformat(),
              'test_type': 'full_dr_simulation',
              'rto_target_minutes': 60,
              'rpo_target_minutes': 15,
              'test_phases': []
          }
          
          # Phase 1: Simulate failure
          start_time = datetime.now()
          failed_instances = simulate_primary_failure()
          test_results['test_phases'].append({
              'phase': 'failure_simulation',
              'status': 'completed',
              'instances_affected': len(failed_instances),
              'duration_seconds': (datetime.now() - start_time).total_seconds()
          })
          
          # Phase 2: Activate DR
          start_time = datetime.now()
          dr_activation = activate_dr_site()
          activation_duration = (datetime.now() - start_time).total_seconds()
          test_results['test_phases'].append({
              'phase': 'dr_activation',
              'status': 'completed',
              'details': dr_activation,
              'duration_seconds': activation_duration
          })
          
          # Phase 3: Verify functionality
          start_time = datetime.now()
          health_checks = verify_dr_functionality()
          test_results['test_phases'].append({
              'phase': 'functionality_verification',
              'status': 'completed',
              'health_checks': health_checks,
              'duration_seconds': (datetime.now() - start_time).total_seconds()
          })
          
          # Phase 4: Restore primary
          start_time = datetime.now()
          restoration = restore_primary_site(failed_instances)
          test_results['test_phases'].append({
              'phase': 'primary_restoration',
              'status': 'completed',
              'details': restoration,
              'duration_seconds': (datetime.now() - start_time).total_seconds()
          })
          
          # Calculate metrics
          total_rto = sum(p['duration_seconds'] for p in test_results['test_phases'][:2]) / 60  # RTO in minutes
          test_results['actual_rto_minutes'] = total_rto
          test_results['rto_met'] = total_rto <= test_results['rto_target_minutes']
          test_results['test_success'] = all(p['status'] == 'completed' for p in test_results['test_phases'])
          
          with open('dr-test-results.json', 'w') as f:
              json.dump(test_results, f, indent=2)
          
          print(f"ðŸŽ¯ DR Test Results:")
          print(f"  RTO Target: {test_results['rto_target_minutes']} minutes")
          print(f"  Actual RTO: {test_results['actual_rto_minutes']:.2f} minutes")
          print(f"  RTO Met: {'âœ…' if test_results['rto_met'] else 'âŒ'}")
          print(f"  Test Success: {'âœ…' if test_results['test_success'] else 'âŒ'}")
          EOF
          
          python dr-simulation.py

      - name: ðŸ“Š DR Test Analysis
        run: |
          echo "ðŸ“Š Analyzing disaster recovery test results..."
          
          python << 'EOF'
          import json
          from datetime import datetime
          
          with open('dr-test-results.json', 'r') as f:
              results = json.load(f)
          
          # Generate DR assessment
          assessment = {
              'test_date': results['timestamp'],
              'overall_status': 'PASS' if results['test_success'] and results['rto_met'] else 'FAIL',
              'rto_performance': {
                  'target_minutes': results['rto_target_minutes'],
                  'actual_minutes': results['actual_rto_minutes'],
                  'performance_percentage': (results['rto_target_minutes'] / results['actual_rto_minutes']) * 100 if results['actual_rto_minutes'] > 0 else 100
              },
              'phase_analysis': results['test_phases'],
              'recommendations': []
          }
          
          # Generate recommendations
          if not results['rto_met']:
              assessment['recommendations'].append({
                  'priority': 'high',
                  'area': 'RTO Improvement',
                  'description': 'RTO target not met - optimize DR activation process',
                  'actions': [
                      'Pre-provision DR infrastructure',
                      'Implement automated failover',
                      'Optimize backup restore procedures'
                  ]
              })
          
          if results['actual_rto_minutes'] > 30:
              assessment['recommendations'].append({
                  'priority': 'medium',
                  'area': 'Automation',
                  'description': 'Consider increasing automation in DR process',
                  'actions': [
                      'Implement Infrastructure as Code for DR',
                      'Automate DNS failover',
                      'Set up automated health checks'
                  ]
              })
          
          # Save assessment
          with open('dr-assessment-report.json', 'w') as f:
              json.dump(assessment, f, indent=2)
          
          print("ðŸ†˜ Disaster Recovery Assessment Complete")
          print(f"Overall Status: {assessment['overall_status']}")
          print(f"RTO Performance: {assessment['rto_performance']['performance_percentage']:.1f}%")
          print(f"Recommendations: {len(assessment['recommendations'])}")
          EOF

      - name: ðŸ“¤ Upload DR Reports
        uses: actions/upload-artifact@v4
        with:
          name: disaster-recovery-reports
          path: |
            dr-test-results.json
            dr-assessment-report.json
          retention-days: 90

  # ==========================================
  # INFRASTRUCTURE CLEANUP
  # ==========================================
  infrastructure-cleanup:
    name: ðŸ§¹ Infrastructure Cleanup
    runs-on: ubuntu-latest
    needs: infrastructure-validation
    if: github.event.inputs.action == 'destroy'
    timeout-minutes: 30
    steps:
      - name: ðŸ“¥ Checkout Infrastructure Code
        uses: actions/checkout@v4

      - name: ðŸ—ï¸ Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: ðŸ—‘ï¸ Terraform Destroy
        run: |
          echo "ðŸ—‘ï¸ Destroying infrastructure resources..."
          
          cd infrastructure/${{ needs.infrastructure-validation.outputs.cloud-provider }}/${{ needs.infrastructure-validation.outputs.environment }}
          
          terraform init \
            -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
            -backend-config="key=${{ needs.infrastructure-validation.outputs.environment }}/${{ needs.infrastructure-validation.outputs.cloud-provider }}/terraform.tfstate"
          
          terraform destroy -auto-approve \
            -var="environment=${{ needs.infrastructure-validation.outputs.environment }}"
          
          echo "âœ… Infrastructure destruction completed"

  # ==========================================
  # MEMORY STORAGE & REPORTING
  # ==========================================
  infrastructure-reporting:
    name: ðŸ“‹ Infrastructure Reporting & Memory Storage
    runs-on: ubuntu-latest
    needs: [infrastructure-validation, terraform-apply, cost-optimization, disaster-recovery]
    if: always()
    steps:
      - name: ðŸ’¾ Store Infrastructure Patterns in Memory
        run: |
          echo "ðŸ’¾ Storing infrastructure patterns in memory..."
          
          # Create infrastructure patterns document
          cat > infrastructure-patterns.json << 'EOF'
          {
            "hive_path": "hive/infrastructure/enterprise-automation",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "patterns": {
              "terraform_workflows": {
                "validation_pipeline": {
                  "security_scanning": ["checkov", "tfsec", "terrascan"],
                  "cost_estimation": "infracost",
                  "compliance_assessment": "custom_scoring",
                  "quality_gates": ["security", "compliance", "cost"]
                },
                "deployment_pipeline": {
                  "strategies": ["plan", "apply", "destroy"],
                  "approval_mechanisms": ["manual", "auto_approve", "emergency_mode"],
                  "health_checks": "provider_specific",
                  "backup_procedures": "state_file_backup"
                }
              },
              "multi_cloud_support": {
                "aws": {
                  "services": ["EC2", "ELB", "RDS", "CloudWatch", "S3"],
                  "cost_tools": ["AWS_Cost_Explorer", "infracost"],
                  "monitoring": "CloudWatch",
                  "backup": "EBS_Snapshots"
                },
                "azure": {
                  "services": ["VM", "Load_Balancer", "SQL_Database", "Monitor"],
                  "cost_tools": ["Azure_Cost_Management"],
                  "monitoring": "Azure_Monitor",
                  "backup": "Azure_Backup"
                },
                "gcp": {
                  "services": ["Compute_Engine", "Load_Balancing", "Cloud_SQL"],
                  "cost_tools": ["Cloud_Billing_API"],
                  "monitoring": "Cloud_Monitoring",
                  "backup": "Persistent_Disk_Snapshots"
                }
              },
              "cost_optimization": {
                "analysis_frequency": "daily",
                "optimization_strategies": [
                  "reserved_instances",
                  "spot_instances",
                  "rightsizing",
                  "auto_scaling"
                ],
                "thresholds": {
                  "warning": 1000,
                  "critical": 5000
                },
                "tools": ["infracost", "cloud_native_apis", "custom_scripts"]
              },
              "disaster_recovery": {
                "testing_frequency": "weekly",
                "rto_target": "60_minutes",
                "rpo_target": "15_minutes",
                "test_phases": [
                  "failure_simulation",
                  "dr_activation",
                  "functionality_verification",
                  "primary_restoration"
                ],
                "automation_level": "semi_automated"
              },
              "compliance_security": {
                "security_tools": ["checkov", "tfsec", "terrascan"],
                "compliance_areas": [
                  "resource_tagging",
                  "encryption_configuration",
                  "backup_requirements",
                  "monitoring_setup"
                ],
                "scoring_mechanism": "percentage_based",
                "remediation": "automated_recommendations"
              }
            },
            "best_practices": {
              "infrastructure_as_code": [
                "Use_version_controlled_terraform",
                "Implement_state_file_locking",
                "Separate_environments_by_workspace",
                "Use_modules_for_reusability"
              ],
              "security": [
                "Scan_infrastructure_code",
                "Implement_least_privilege",
                "Enable_encryption_at_rest",
                "Regular_security_audits"
              ],
              "cost_management": [
                "Implement_tagging_strategy",
                "Regular_cost_reviews",
                "Use_reserved_instances",
                "Implement_auto_scaling"
              ],
              "disaster_recovery": [
                "Regular_DR_testing",
                "Automated_backup_procedures",
                "Cross_region_replication",
                "Documentation_maintenance"
              ]
            },
            "metrics": {
              "deployment_frequency": "on_demand",
              "change_failure_rate": "target_less_than_5_percent",
              "mean_time_to_recovery": "target_less_than_1_hour",
              "cost_optimization_percentage": "target_20_percent_savings"
            }
          }
          EOF
          
          echo "ðŸ“Š Infrastructure patterns documented"

      - name: ðŸ“‹ Generate Final Infrastructure Report
        run: |
          echo "ðŸ“‹ Generating comprehensive infrastructure report..."
          
          cat > infrastructure-final-report.md << 'EOF'
          # ðŸ—ï¸ Infrastructure Automation Report
          
          **Date**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Pipeline Run**: ${{ github.run_id }}
          **Environment**: ${{ needs.infrastructure-validation.outputs.environment || 'N/A' }}
          **Cloud Provider**: ${{ needs.infrastructure-validation.outputs.cloud-provider || 'N/A' }}
          
          ## ðŸ“Š Execution Summary
          
          | Component | Status | Details |
          |-----------|--------|---------|
          | Infrastructure Validation | ${{ needs.infrastructure-validation.result }} | Security: ${{ needs.infrastructure-validation.outputs.security-passed }}, Compliance: ${{ needs.infrastructure-validation.outputs.compliance-score }}% |
          | Terraform Deployment | ${{ needs.terraform-apply.result || 'Skipped' }} | Changes: ${{ needs.infrastructure-validation.outputs.terraform-changes }} |
          | Cost Optimization | ${{ needs.cost-optimization.result || 'Skipped' }} | Monthly Estimate: ${{ needs.infrastructure-validation.outputs.cost-estimate }} |
          | Disaster Recovery | ${{ needs.disaster-recovery.result || 'Skipped' }} | RTO Target: 60min, RPO Target: 15min |
          
          ## ðŸ” Key Metrics
          
          - **Infrastructure Changes**: ${{ needs.infrastructure-validation.outputs.terraform-changes == 'true' && 'Yes' || 'No' }}
          - **Security Compliance**: ${{ needs.infrastructure-validation.outputs.security-passed == 'true' && 'Passed' || 'Failed' }}
          - **Compliance Score**: ${{ needs.infrastructure-validation.outputs.compliance-score || 'N/A' }}%
          - **Estimated Monthly Cost**: ${{ needs.infrastructure-validation.outputs.cost-estimate || 'N/A' }}
          
          ## ðŸŽ¯ Recommendations
          
          1. **Security**: Continue regular security scanning and address any findings
          2. **Cost Optimization**: Review cost optimization reports for potential savings
          3. **Disaster Recovery**: Ensure DR tests meet RTO/RPO targets
          4. **Compliance**: Maintain compliance score above 90%
          
          ## ðŸ“š Documentation
          
          - Infrastructure patterns stored in: `hive/infrastructure/enterprise-automation`
          - Security scan results: Available in artifacts
          - Cost analysis reports: Available in artifacts
          - DR test results: Available in artifacts
          
          ## ðŸ”„ Next Actions
          
          1. Review any failed components and remediate issues
          2. Implement cost optimization recommendations
          3. Schedule next disaster recovery test
          4. Update infrastructure documentation
          
          ---
          
          *This report was automatically generated by the Infrastructure Automation Pipeline*
          EOF

      - name: ðŸ“¤ Upload Final Reports
        uses: actions/upload-artifact@v4
        with:
          name: infrastructure-final-report
          path: |
            infrastructure-patterns.json
            infrastructure-final-report.md
          retention-days: 90

      - name: ðŸ“¢ Send Infrastructure Notification
        if: always()
        run: |
          echo "ðŸ“¢ Sending infrastructure automation notification..."
          
          # Determine overall status
          if [ "${{ needs.infrastructure-validation.result }}" = "success" ]; then
            if [ "${{ needs.terraform-apply.result }}" = "success" ] || [ "${{ needs.terraform-apply.result }}" = "skipped" ]; then
              STATUS="âœ… SUCCESS"
              COLOR="good"
            else
              STATUS="âš ï¸ PARTIAL"
              COLOR="warning"
            fi
          else
            STATUS="âŒ FAILED"
            COLOR="danger"
          fi
          
          echo "ðŸ“Š Infrastructure Automation Status: $STATUS"
          echo "ðŸŽ¯ Environment: ${{ needs.infrastructure-validation.outputs.environment }}"
          echo "â˜ï¸ Cloud Provider: ${{ needs.infrastructure-validation.outputs.cloud-provider }}"
          echo "ðŸ’° Estimated Cost: ${{ needs.infrastructure-validation.outputs.cost-estimate }}"
          
          # Send notification if webhook is configured
          if [ -n "${{ secrets.SLACK_WEBHOOK_URL }}" ]; then
            curl -X POST -H 'Content-type: application/json' \
              --data "{\"text\":\"ðŸ—ï¸ Infrastructure Automation $STATUS\\nðŸŽ¯ Environment: ${{ needs.infrastructure-validation.outputs.environment }}\\nâ˜ï¸ Provider: ${{ needs.infrastructure-validation.outputs.cloud-provider }}\\nðŸ’° Cost: ${{ needs.infrastructure-validation.outputs.cost-estimate }}\"}" \
              ${{ secrets.SLACK_WEBHOOK_URL }}
          fi