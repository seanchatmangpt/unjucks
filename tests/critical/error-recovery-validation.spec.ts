/**
 * 80/20 Error Recovery Validation Suite
 * Tests critical error handling and system reliability scenarios
 */
import { describe, test, expect, beforeEach } from 'vitest';
import { TurtleParser, TurtleParseError } from '../../src/lib/turtle-parser.js';
import { RDFDataLoader } from '../../src/lib/rdf-data-loader.js';
import { readFileSync, existsSync } from 'node:fs';
import { join } from 'node:path';
import { performance } from 'node:perf_hooks';

describe('80/20 Error Recovery Validation', () => {
  let parser: TurtleParser;
  let dataLoader: RDFDataLoader;

  beforeEach(() => {
    parser = new TurtleParser();
    dataLoader = new RDFDataLoader();
  });

  // Test 1: Graceful Syntax Error Handling (10% coverage, critical for reliability)
  // This test validates that parsing errors provide actionable diagnostic information
  test('Handle malformed RDF with detailed error reporting', async () => {
    let invalidData: string;
    
    // Try to use fixture file, fallback to inline data
    const invalidFilePath = join(process.cwd(), 'tests/fixtures/turtle/invalid-syntax.ttl');
    if (existsSync(invalidFilePath)) {
      invalidData = readFileSync(invalidFilePath, 'utf-8');
    } else {
      invalidData = `
        @prefix foaf: <http://xmlns.com/foaf/0.1/> .
        @prefix ex: <http://example.org/> .
        
        ex:person1 foaf:name "John Doe" ;
                   foaf:email "missing-quote-here ;
                   foaf:age "30" .
                   # Error: unclosed string literal above
        
        ex:person2 foaf:name "Jane Smith" 
                   # Error: missing semicolon or period above
      `;
    }
    
    let parseError: TurtleParseError;
    try {
      await parser.parse(invalidData);
    } catch (error) {
      parseError = error as TurtleParseError;
    }
    
    // CRITICAL ERROR RECOVERY VALIDATION
    
    // 1. Error caught and properly wrapped
    expect(parseError!).toBeInstanceOf(TurtleParseError);
    expect(parseError!.name).toBe('TurtleParseError');
    expect(parseError!.message).toMatch(/Failed to parse Turtle/);
    
    // 2. Diagnostic information provided for debugging
    expect(parseError!.line).toBeDefined();
    expect(parseError!.column).toBeDefined();
    expect(parseError!.originalError).toBeDefined();
    expect(typeof parseError!.line).toBe('number');
    expect(typeof parseError!.column).toBe('number');
    
    console.log(`Error at line ${parseError!.line}, column ${parseError!.column}: ${parseError!.message}`);
    
    // 3. System stability maintained - no crashes or hangs
    expect(parseError!).toBeInstanceOf(Error);
    expect(parseError!.originalError).toBeInstanceOf(Error);
    
    // 4. Parser can recover and continue working after error
    const validData = `
      @prefix ex: <http://example.org/> .
      <#test> ex:name "Recovery Test" ;
              ex:status "working" .
    `;
    const recoveryResult = await parser.parse(validData);
    expect(recoveryResult.triples.length).toBe(2);
    expect(recoveryResult.stats.tripleCount).toBe(2);
  });

  // Test 2: Large Dataset Memory Stability (5% coverage, critical for enterprise)
  // Validates system maintains stable memory usage over extended operation
  test('Maintain memory stability with repeated large operations', async () => {
    const iterations = 8;
    const memoryReadings: number[] = [];
    const parseTimings: number[] = [];
    
    // Generate consistent test data for each iteration
    const testDataSize = 1500; // 1.5K triples per iteration
    
    for (let i = 0; i < iterations; i++) {
      // Force garbage collection if available
      if (global.gc) {
        global.gc();
        // Wait for GC to complete
        await new Promise(resolve => setTimeout(resolve, 100));
      }
      
      const testData = generateLargeTestDataset(testDataSize, i);
      const memoryBefore = process.memoryUsage().heapUsed;
      const startTime = performance.now();
      
      const result = await parser.parse(testData);
      
      const endTime = performance.now();
      parseTimings.push(endTime - startTime);
      
      // Validate each iteration
      expect(result.triples.length).toBe(testDataSize);
      expect(result.stats.tripleCount).toBe(testDataSize);
      
      // Record memory after GC
      if (global.gc) {
        global.gc();
        await new Promise(resolve => setTimeout(resolve, 50));
      }
      
      const memoryAfter = process.memoryUsage().heapUsed;
      memoryReadings.push(memoryAfter);
      
      console.log(`Iteration ${i + 1}: Parse time ${(endTime - startTime).toFixed(2)}ms, Memory: ${(memoryAfter / 1024 / 1024).toFixed(2)}MB`);
    }
    
    // MEMORY STABILITY VALIDATION
    
    // 1. No significant memory leaks
    const initialMemory = memoryReadings[0];
    const finalMemory = memoryReadings[iterations - 1];
    const memoryGrowth = finalMemory - initialMemory;
    const acceptableGrowth = 30 * 1024 * 1024; // 30MB max growth
    
    expect(memoryGrowth).toBeLessThan(acceptableGrowth);
    console.log(`Memory growth over ${iterations} iterations: ${(memoryGrowth / 1024 / 1024).toFixed(2)}MB`);
    
    // 2. Performance stability - parsing time should remain consistent
    const averageTime = parseTimings.reduce((sum, time) => sum + time, 0) / parseTimings.length;
    const minTime = Math.min(...parseTimings);
    const maxTime = Math.max(...parseTimings);
    const maxDeviation = maxTime - minTime;
    
    // Performance should not degrade significantly
    expect(maxDeviation).toBeLessThan(averageTime * 0.8); // 80% max variation
    expect(averageTime).toBeLessThan(1000); // Average should be under 1 second
    
    console.log(`Performance: avg ${averageTime.toFixed(2)}ms, min ${minTime.toFixed(2)}ms, max ${maxTime.toFixed(2)}ms`);
    
    // 3. Memory usage should be reasonable for dataset size
    const finalMemoryMB = finalMemory / 1024 / 1024;
    expect(finalMemoryMB).toBeLessThan(300); // 300MB max stable memory
  });

  // Test 3: Edge Case Handling (5% coverage, critical for reliability)
  // Validates handling of edge cases that could break enterprise systems
  test('Handle edge cases gracefully without failure', async () => {
    // EDGE CASE VALIDATION (critical for enterprise reliability)
    
    // 1. Empty content
    const emptyResult = await parser.parse('');
    expect(emptyResult.triples).toHaveLength(0);
    expect(emptyResult.stats.tripleCount).toBe(0);
    expect(emptyResult.prefixes).toEqual({});
    expect(emptyResult.namedGraphs).toHaveLength(0);
    
    // 2. Comments only
    const commentsOnly = await parser.parse(`
      # This is just a comment
      # Another comment with special chars: Ã Ã¡Ã¢Ã£Ã¤Ã¥ Ã¦ Ã§ Ã¨Ã©ÃªÃ«
      # No actual RDF data here
      # Yet another comment with numbers: 12345 and symbols: !@#$%^&*()
    `);
    expect(commentsOnly.triples).toHaveLength(0);
    expect(commentsOnly.stats.tripleCount).toBe(0);
    expect(commentsOnly.prefixes).toEqual({});
    
    // 3. Whitespace only variations
    const whitespaceVariations = [
      '   \n\t  \n   \r\n  ',
      '\t\t\t',
      '\n\n\n\n',
      '        ',
      ' \r\n \t \n \r ',
    ];
    
    for (const whitespace of whitespaceVariations) {
      const result = await parser.parse(whitespace);
      expect(result.triples).toHaveLength(0);
      expect(result.stats.tripleCount).toBe(0);
    }
    
    // 4. Single triple (minimal valid RDF)
    const singleTriple = await parser.parse('<#s> <#p> <#o> .');
    expect(singleTriple.triples).toHaveLength(1);
    expect(singleTriple.stats.tripleCount).toBe(1);
    expect(singleTriple.triples[0].subject.value).toBe('#s');
    expect(singleTriple.triples[0].predicate.value).toBe('#p');
    expect(singleTriple.triples[0].object.value).toBe('#o');
    
    // 5. Unicode handling (critical for international enterprise deployment)
    const unicodeData = `
      @prefix ex: <http://example.org/> .
      @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
      
      <#test> ex:name "æµ‹è¯•ç”¨æˆ·" ;
              ex:description "Ð¢ÐµÑÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ" ;
              ex:emoji "ðŸš€ðŸŒŸðŸ’»" ;
              rdfs:label "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" ;
              ex:japanese "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ" ;
              ex:korean "ì•ˆë…•í•˜ì„¸ìš” ì„¸ê³„" .
    `;
    
    const unicodeResult = await parser.parse(unicodeData);
    expect(unicodeResult.triples.length).toBeGreaterThan(5);
    
    const nameTriple = unicodeResult.triples.find(t => 
      t.predicate.value.includes('name')
    );
    expect(nameTriple?.object.value).toBe('æµ‹è¯•ç”¨æˆ·');
    
    const emojiTriple = unicodeResult.triples.find(t =>
      t.predicate.value.includes('emoji')
    );
    expect(emojiTriple?.object.value).toBe('ðŸš€ðŸŒŸðŸ’»');
    
    // 6. Very long literals (enterprise data can have long descriptions)
    const longDescription = 'A'.repeat(10000); // 10K character string
    const longLiteralData = `
      @prefix ex: <http://example.org/> .
      <#test> ex:longDescription "${longDescription}" .
    `;
    
    const longResult = await parser.parse(longLiteralData);
    expect(longResult.triples).toHaveLength(1);
    expect(longResult.triples[0].object.value).toBe(longDescription);
    expect(longResult.triples[0].object.value.length).toBe(10000);
    
    // 7. Mixed content (comments + data + whitespace)
    const mixedContent = `
      # Initial comment
      @prefix ex: <http://example.org/> .
      
      # Another comment
      <#s1> ex:p1 "value1" .
      
      
      # More comments with empty lines above
      <#s2> ex:p2 "value2" .
    `;
    
    const mixedResult = await parser.parse(mixedContent);
    expect(mixedResult.triples).toHaveLength(2);
    expect(mixedResult.prefixes).toHaveProperty('ex');
  });

  // Test 4: Network/File System Error Recovery (5% coverage)
  // Validates handling of external resource failures
  test('Handle file system and network errors gracefully', async () => {
    // FILE SYSTEM ERROR VALIDATION
    
    // 1. Non-existent file
    let fileError: any;
    try {
      await dataLoader.loadFromSource({ 
        type: 'file', 
        path: '/nonexistent/path/invalid.ttl' 
      });
    } catch (error) {
      fileError = error;
    }
    
    expect(fileError).toBeDefined();
    expect(fileError.message).toMatch(/file read error|not found/i);
    
    // 2. Permission denied simulation (if possible)
    // This would be system-specific, so we'll simulate with invalid data
    
    // 3. System can continue after file errors
    const validFile = join(process.cwd(), 'tests/fixtures/turtle/basic-person.ttl');
    if (existsSync(validFile)) {
      const recoveryResult = await dataLoader.loadFromSource({ 
        type: 'file', 
        path: validFile 
      });
      expect(recoveryResult.success).toBe(true);
      expect(recoveryResult.triples.length).toBeGreaterThan(0);
    }
    
    // 4. Invalid inline data handling
    let inlineError: any;
    try {
      await dataLoader.loadFromSource({
        type: 'inline',
        content: 'completely invalid turtle data with no structure at all!'
      });
    } catch (error) {
      inlineError = error;
    }
    
    expect(inlineError).toBeDefined();
    
    // 5. System recovery after inline errors
    const validInlineResult = await dataLoader.loadFromSource({
      type: 'inline',
      content: '@prefix ex: <http://example.org/> . <#test> ex:name "Recovery" .'
    });
    expect(validInlineResult.success).toBe(true);
    expect(validInlineResult.triples.length).toBe(1);
  });

  // Test 5: Concurrent Error Handling (3% coverage)
  // Validates error isolation in concurrent operations
  test('Isolate errors in concurrent parsing operations', async () => {
    const validData = '@prefix ex: <http://example.org/> . <#test> ex:name "Valid" .';
    const invalidData = '@prefix invalid < malformed turtle data ;';
    
    // Mix valid and invalid parsing operations
    const operations = [
      parser.parse(validData),
      parser.parse(invalidData).catch(error => ({ error })),
      parser.parse(validData),
      parser.parse(invalidData).catch(error => ({ error })),
      parser.parse(validData),
    ];
    
    const results = await Promise.all(operations);
    
    // CONCURRENT ERROR ISOLATION VALIDATION
    
    // 1. Valid operations should succeed
    const validResults = results.filter(result => !('error' in result));
    expect(validResults).toHaveLength(3);
    validResults.forEach(result => {
      expect((result as any).triples.length).toBe(1);
    });
    
    // 2. Invalid operations should fail gracefully
    const errorResults = results.filter(result => 'error' in result);
    expect(errorResults).toHaveLength(2);
    errorResults.forEach(result => {
      expect((result as any).error).toBeInstanceOf(TurtleParseError);
    });
    
    // 3. Errors don't affect other operations
    expect(validResults.length + errorResults.length).toBe(5);
    
    // 4. System remains stable after mixed success/failure
    const postTestResult = await parser.parse(validData);
    expect(postTestResult.triples.length).toBe(1);
  });
});

/**
 * Generate large test dataset for memory stability testing
 */
function generateLargeTestDataset(tripleCount: number, seed: number): string {
  let content = `
    @prefix ex: <http://example.org/test${seed}/> .
    @prefix foaf: <http://xmlns.com/foaf/0.1/> .
    @prefix schema: <http://schema.org/> .
    @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
  `;
  
  const entitiesCount = Math.floor(tripleCount / 5); // ~5 triples per entity
  
  for (let i = 0; i < entitiesCount; i++) {
    const entityId = `entity${seed}_${i}`;
    content += `
      ex:${entityId} a foaf:Person ;
          foaf:name "Test Person ${seed}-${i}" ;
          schema:email "${entityId}@test${seed}.example.org" ;
          foaf:age "${20 + (i % 50)}"^^xsd:integer ;
          ex:testIteration "${seed}"^^xsd:integer .
    `;
  }
  
  return content;
}