#!/usr/bin/env tsx\n/**\n * BDD Test Runner for Unjucks CLI\n * Comprehensive test execution with MCP integration validation\n */\n\nimport { execSync } from 'child_process';\nimport { promises as fs } from 'fs';\nimport path from 'path';\nimport chalk from 'chalk';\n\ninterface TestSuite {\n  name: string;\n  files: string[];\n  description: string;\n  category: 'unit' | 'integration' | 'bdd' | 'performance';\n}\n\nconst testSuites: TestSuite[] = [\n  {\n    name: 'CLI Command BDD Tests',\n    files: ['tests/features/vitest-cucumber-cli.feature.spec.ts'],\n    description: 'Complete CLI command testing with vitest-cucumber framework',\n    category: 'bdd'\n  },\n  {\n    name: 'MCP Integration Tests',\n    files: ['tests/features/mcp-integration-complete.feature.spec.ts'],\n    description: 'Comprehensive MCP tool integration and Claude-Flow coordination',\n    category: 'integration'\n  },\n  {\n    name: 'Semantic RDF & Swarm Tests',\n    files: ['tests/features/semantic-swarm-integration.feature.spec.ts'],\n    description: 'Semantic RDF processing with distributed swarm coordination',\n    category: 'bdd'\n  },\n  {\n    name: 'User Journey Tests',\n    files: ['tests/features/user-journey-comprehensive.feature.spec.ts'],\n    description: 'End-to-end user scenarios and complete workflows',\n    category: 'bdd'\n  },\n  {\n    name: 'Existing Core Tests',\n    files: [\n      'tests/generator.test.ts',\n      'tests/template-scanner.test.ts',\n      'tests/validation/rdf-data-validation.test.ts',\n      'tests/validation/rdf-template-validation.test.ts'\n    ],\n    description: 'Core functionality validation and RDF processing',\n    category: 'unit'\n  }\n];\n\ninterface TestResults {\n  suite: string;\n  passed: boolean;\n  duration: number;\n  error?: string;\n  details?: any;\n}\n\nclass BDDTestRunner {\n  private results: TestResults[] = [];\n  private totalStartTime = Date.now();\n\n  async run(suiteFilter?: string) {\n    console.log(chalk.blue.bold('🧪 Unjucks BDD Test Suite Runner'));\n    console.log(chalk.gray('Comprehensive testing with vitest-cucumber and MCP integration\\n'));\n\n    // Filter test suites if requested\n    const suitesToRun = suiteFilter \n      ? testSuites.filter(suite => suite.name.toLowerCase().includes(suiteFilter.toLowerCase()))\n      : testSuites;\n\n    if (suitesToRun.length === 0) {\n      console.log(chalk.red(`No test suites found matching: ${suiteFilter}`));\n      process.exit(1);\n    }\n\n    console.log(chalk.yellow(`Running ${suitesToRun.length} test suite(s):`));\n    suitesToRun.forEach(suite => {\n      console.log(chalk.gray(`  • ${suite.name} (${suite.category})`));\n    });\n    console.log();\n\n    // Pre-flight checks\n    await this.preFlightChecks();\n\n    // Run each test suite\n    for (const suite of suitesToRun) {\n      await this.runTestSuite(suite);\n    }\n\n    // Generate final report\n    await this.generateReport();\n  }\n\n  private async preFlightChecks() {\n    console.log(chalk.cyan('🔧 Pre-flight checks...'));\n\n    // Check if build exists\n    try {\n      await fs.access('dist/cli.js');\n      console.log(chalk.green('  ✓ CLI build exists'));\n    } catch {\n      console.log(chalk.yellow('  ⚠ CLI build not found, building...'));\n      try {\n        execSync('npm run build', { stdio: 'inherit' });\n        console.log(chalk.green('  ✓ CLI built successfully'));\n      } catch (error) {\n        console.log(chalk.red('  ✗ CLI build failed'));\n        throw error;\n      }\n    }\n\n    // Check test fixtures\n    try {\n      await fs.access('tests/fixtures/templates/sample');\n      console.log(chalk.green('  ✓ Test fixtures available'));\n    } catch {\n      console.log(chalk.yellow('  ⚠ Test fixtures missing, some tests may fail'));\n    }\n\n    // Check MCP integration setup\n    const mcpUrl = process.env.CLAUDE_FLOW_MCP_URL || 'http://localhost:3000';\n    console.log(chalk.green(`  ✓ MCP server configured: ${mcpUrl}`));\n\n    console.log();\n  }\n\n  private async runTestSuite(suite: TestSuite) {\n    const startTime = Date.now();\n    console.log(chalk.cyan(`🧪 Running: ${suite.name}`));\n    console.log(chalk.gray(`   ${suite.description}`));\n\n    try {\n      // Prepare test environment\n      process.env.NODE_ENV = 'test';\n      process.env.UNJUCKS_TEST_MODE = 'true';\n\n      // Run vitest on the specific test files\n      const testFiles = suite.files.filter(file => {\n        try {\n          require.resolve(path.resolve(file));\n          return true;\n        } catch {\n          console.log(chalk.yellow(`     ⚠ Skipping ${file} (not found)`));\n          return false;\n        }\n      });\n\n      if (testFiles.length === 0) {\n        throw new Error('No test files found for this suite');\n      }\n\n      const cmd = `npx vitest run ${testFiles.join(' ')} --reporter=verbose`;\n      const output = execSync(cmd, { \n        encoding: 'utf8',\n        cwd: process.cwd(),\n        env: { ...process.env }\n      });\n\n      const duration = Date.now() - startTime;\n      console.log(chalk.green(`   ✓ Passed (${duration}ms)`));\n      \n      this.results.push({\n        suite: suite.name,\n        passed: true,\n        duration,\n        details: { output: output.slice(-500) } // Last 500 chars\n      });\n\n    } catch (error: any) {\n      const duration = Date.now() - startTime;\n      console.log(chalk.red(`   ✗ Failed (${duration}ms)`));\n      console.log(chalk.red(`     Error: ${error.message.split('\\n')[0]}`));\n      \n      this.results.push({\n        suite: suite.name,\n        passed: false,\n        duration,\n        error: error.message\n      });\n    }\n\n    console.log();\n  }\n\n  private async generateReport() {\n    const totalDuration = Date.now() - this.totalStartTime;\n    const passed = this.results.filter(r => r.passed).length;\n    const failed = this.results.filter(r => !r.passed).length;\n\n    console.log(chalk.blue.bold('📊 Test Results Summary'));\n    console.log(chalk.gray('=' .repeat(50)));\n    console.log();\n\n    // Suite-by-suite results\n    this.results.forEach(result => {\n      const status = result.passed ? chalk.green('✓ PASS') : chalk.red('✗ FAIL');\n      const duration = chalk.gray(`(${result.duration}ms)`);\n      console.log(`${status} ${result.suite} ${duration}`);\n      \n      if (!result.passed && result.error) {\n        console.log(chalk.red(`      ${result.error.split('\\n')[0]}`));\n      }\n    });\n\n    console.log();\n    console.log(chalk.gray('-'.repeat(50)));\n    \n    // Overall statistics\n    const totalTests = passed + failed;\n    console.log(chalk.yellow(`Total Suites: ${totalTests}`));\n    console.log(chalk.green(`Passed: ${passed}`));\n    console.log(chalk.red(`Failed: ${failed}`));\n    console.log(chalk.gray(`Duration: ${totalDuration}ms`));\n    \n    const successRate = totalTests > 0 ? (passed / totalTests * 100).toFixed(1) : '0';\n    console.log(chalk.cyan(`Success Rate: ${successRate}%`));\n    console.log();\n\n    // Generate detailed report file\n    const reportPath = 'tests/reports/bdd-test-results.json';\n    await fs.mkdir('tests/reports', { recursive: true });\n    \n    const report = {\n      timestamp: new Date().toISOString(),\n      summary: {\n        total: totalTests,\n        passed,\n        failed,\n        successRate: parseFloat(successRate),\n        duration: totalDuration\n      },\n      suites: this.results,\n      environment: {\n        nodeVersion: process.version,\n        platform: process.platform,\n        mcpUrl: process.env.CLAUDE_FLOW_MCP_URL || 'http://localhost:3000'\n      }\n    };\n\n    await fs.writeFile(reportPath, JSON.stringify(report, null, 2));\n    console.log(chalk.gray(`Detailed report saved: ${reportPath}`));\n\n    // Exit with appropriate code\n    if (failed > 0) {\n      console.log(chalk.red.bold('\\n❌ Some tests failed'));\n      process.exit(1);\n    } else {\n      console.log(chalk.green.bold('\\n✅ All tests passed!'));\n      process.exit(0);\n    }\n  }\n}\n\n// CLI interface\nconst args = process.argv.slice(2);\nconst suiteFilter = args[0];\n\nconst runner = new BDDTestRunner();\nrunner.run(suiteFilter).catch(error => {\n  console.error(chalk.red('Test runner failed:'), error);\n  process.exit(1);\n});"