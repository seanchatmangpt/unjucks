#!/usr/bin/env node
/**
 * Master Test Orchestrator for @seanchatmangpt/unjucks
 * 
 * MISSION: Run ALL tests and generate comprehensive production readiness report
 * 
 * This is the definitive entry point that proves everything works.
 * Orchestrates all test suites, collects metrics, and provides production readiness scoring.
 * 
 * Features:
 * - Clean Docker environment setup
 * - Sequential test suite execution
 * - Comprehensive result collection
 * - HTML/JSON/MD report generation
 * - Production readiness scoring
 * - Performance metrics
 * - Security validation
 * - Coverage analysis
 */

import { execSync, exec } from 'child_process';
import fs from 'fs/promises';
import { createReadStream, existsSync } from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { promisify } from 'util';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const projectRoot = path.resolve(__dirname, '../..');

const execAsync = promisify(exec);

/**
 * Master Test Orchestrator
 * Coordinates all testing activities and generates comprehensive reports
 */
class MasterTestOrchestrator {
  constructor() {
    this.startTime = this.getDeterministicTimestamp();
    this.results = {
      environment: null,
      testSuites: {},
      metrics: {
        performance: {},
        security: {},
        coverage: {},
        reliability: {}
      },
      summary: {
        total_tests: 0,
        total_passed: 0,
        total_failed: 0,
        total_skipped: 0,
        overall_success_rate: 0,
        production_ready: false,
        readiness_score: 0
      }
    };

    this.testSuites = [
      {
        name: 'smoke',
        description: 'Basic smoke tests - CLI functionality',
        path: '../smoke/',
        pattern: '*.test.js',
        weight: 0.15,
        critical: true
      },
      {
        name: 'unit-core',
        description: 'Core unit tests - filters and utilities',
        path: '../unit/',
        pattern: '*.test.js',
        weight: 0.20,
        critical: true
      },
      {
        name: 'filters',
        description: 'Template filter tests',
        path: '../filters/',
        pattern: '**/*.test.js',
        weight: 0.15,
        critical: true
      },
      {
        name: 'cli-comprehensive',
        description: 'Comprehensive CLI tests',
        path: '../cli-comprehensive/',
        pattern: 'run-all-tests.js',
        weight: 0.15,
        critical: true
      },
      {
        name: 'integration',
        description: 'Integration tests',
        path: '../integration/',
        pattern: '*.test.js',
        weight: 0.10,
        critical: false
      },
      {
        name: 'chaos',
        description: 'Chaos engineering tests',
        path: '../chaos/',
        pattern: 'run-*.js',
        weight: 0.05,
        critical: false
      },
      {
        name: 'stress',
        description: 'Performance and stress tests',
        path: '../stress/',
        pattern: '*.js',
        weight: 0.10,
        critical: false
      },
      {
        name: 'security',
        description: 'Security validation tests',
        path: '../',
        pattern: '*security*.test.js',
        weight: 0.10,
        critical: true
      }
    ];
  }

  /**
   * Set up clean testing environment
   */
  async setupEnvironment() {
    console.log('üê≥ Setting up clean testing environment...');
    
    try {
      // Create test output directory
      await fs.mkdir(path.join(__dirname, 'reports'), { recursive: true });
      await fs.mkdir(path.join(__dirname, 'artifacts'), { recursive: true });

      // Clean up any previous test artifacts
      const cleanupPaths = [
        path.join(projectRoot, 'test-*.html'),
        path.join(projectRoot, 'test-*.md'),
        path.join(projectRoot, 'test-*.tex'),
        path.join(projectRoot, '.tmp'),
        path.join(projectRoot, 'coverage')
      ];

      for (const cleanPath of cleanupPaths) {
        try {
          await fs.rm(cleanPath, { recursive: true, force: true });
        } catch (error) {
          // Ignore cleanup errors
        }
      }

      // Collect environment information
      this.results.environment = {
        timestamp: this.getDeterministicDate().toISOString(),
        node_version: process.version,
        platform: process.platform,
        arch: process.arch,
        memory: process.memoryUsage(),
        cwd: process.cwd(),
        cli_version: await this.getCLIVersion(),
        package_info: await this.getPackageInfo()
      };

      console.log('‚úÖ Environment setup complete');
      return true;
    } catch (error) {
      console.error('‚ùå Environment setup failed:', error);
      throw error;
    }
  }

  /**
   * Get CLI version information
   */
  async getCLIVersion() {
    try {
      const { stdout } = await execAsync('node bin/unjucks.cjs --version', { 
        cwd: projectRoot,
        timeout: 10000 
      });
      return stdout.trim();
    } catch (error) {
      console.warn('Could not get CLI version:', error.message);
      return 'unknown';
    }
  }

  /**
   * Get package information
   */
  async getPackageInfo() {
    try {
      const packageJson = await fs.readFile(path.join(projectRoot, 'package.json'), 'utf8');
      const pkg = JSON.parse(packageJson);
      return {
        name: pkg.name,
        version: pkg.version,
        description: pkg.description,
        dependencies: Object.keys(pkg.dependencies || {}).length,
        devDependencies: Object.keys(pkg.devDependencies || {}).length
      };
    } catch (error) {
      return { error: error.message };
    }
  }

  /**
   * Run a specific test suite
   */
  async runTestSuite(suite) {
    console.log(`\nüß™ Running ${suite.name} tests: ${suite.description}`);
    console.log(`   Path: ${suite.path}`);
    console.log(`   Pattern: ${suite.pattern}`);
    
    const suiteStart = this.getDeterministicTimestamp();
    const result = {
      name: suite.name,
      description: suite.description,
      weight: suite.weight,
      critical: suite.critical,
      start_time: this.getDeterministicDate().toISOString(),
      duration: 0,
      status: 'running',
      tests_run: 0,
      tests_passed: 0,
      tests_failed: 0,
      tests_skipped: 0,
      success_rate: 0,
      output: '',
      error: null,
      artifacts: []
    };

    try {
      const testPath = path.resolve(__dirname, suite.path);
      let command;
      
      // Determine appropriate test command
      if (suite.name === 'cli-comprehensive') {
        command = `node ${path.join(testPath, 'run-all-tests.js')}`;
      } else if (suite.name === 'chaos') {
        command = `node ${path.join(testPath, 'run-latex-chaos.js')}`;
      } else if (suite.name === 'stress') {
        command = `node ${path.join(testPath, 'load-test.js')}`;
      } else if (suite.pattern.includes('vitest') || suite.name.includes('unit')) {
        command = `npx vitest run ${suite.path} --reporter=json --outputFile=${__dirname}/reports/${suite.name}-results.json`;
      } else {
        // Default to running all JS files in directory
        command = `find ${testPath} -name "${suite.pattern}" -type f | head -10 | xargs -I {} node {}`;
      }

      console.log(`   Command: ${command}`);

      const { stdout, stderr } = await execAsync(command, {
        cwd: projectRoot,
        timeout: 300000, // 5 minutes per suite
        maxBuffer: 1024 * 1024 * 10 // 10MB buffer
      });

      result.output = stdout;
      result.status = 'completed';
      
      // Parse results based on output format
      await this.parseTestResults(result, stdout, stderr);
      
      console.log(`‚úÖ ${suite.name} completed - ${result.tests_passed}/${result.tests_run} passed`);
      
    } catch (error) {
      result.status = 'failed';
      result.error = error.message;
      result.output = error.stdout || '';
      result.tests_failed = 1; // Mark as failed if suite crashes
      
      console.log(`‚ùå ${suite.name} failed: ${error.message}`);
      
      // Non-critical suites can fail without stopping execution
      if (suite.critical) {
        console.warn(`‚ö†Ô∏è  Critical suite ${suite.name} failed - continuing with reduced readiness score`);
      }
    } finally {
      result.duration = this.getDeterministicTimestamp() - suiteStart;
      result.end_time = this.getDeterministicDate().toISOString();
      
      if (result.tests_run > 0) {
        result.success_rate = (result.tests_passed / result.tests_run * 100);
      }

      // Collect any generated artifacts
      await this.collectArtifacts(suite, result);
    }

    this.results.testSuites[suite.name] = result;
    return result;
  }

  /**
   * Parse test results from output
   */
  async parseTestResults(result, stdout, stderr) {
    const lines = stdout.split('\n');
    
    // Look for vitest/jest JSON output
    if (existsSync(path.join(__dirname, 'reports', `${result.name}-results.json`))) {
      try {
        const jsonResults = await fs.readFile(
          path.join(__dirname, 'reports', `${result.name}-results.json`), 
          'utf8'
        );
        const parsed = JSON.parse(jsonResults);
        
        if (parsed.testResults) {
          result.tests_run = parsed.numTotalTests || 0;
          result.tests_passed = parsed.numPassedTests || 0;
          result.tests_failed = parsed.numFailedTests || 0;
          result.tests_skipped = parsed.numPendingTests || 0;
        }
        return;
      } catch (error) {
        console.warn('Could not parse JSON results:', error.message);
      }
    }

    // Parse from text output
    let testsRun = 0;
    let testsPassed = 0;
    let testsFailed = 0;
    
    for (const line of lines) {
      // Look for common test output patterns
      if (line.includes('‚úÖ') || line.includes('passed')) testsRun++;
      if (line.includes('‚ùå') || line.includes('failed')) { testsRun++; testsFailed++; }
      if (line.includes('‚è≠Ô∏è') || line.includes('skipped')) testsRun++;
      
      // CLI test specific patterns
      if (line.includes('Total Tests Run:')) {
        const match = line.match(/(\d+)/);
        if (match) testsRun = parseInt(match[1]);
      }
      if (line.includes('Passed:')) {
        const match = line.match(/(\d+)/);
        if (match) testsPassed = parseInt(match[1]);
      }
      if (line.includes('Failed:')) {
        const match = line.match(/(\d+)/);
        if (match) testsFailed = parseInt(match[1]);
      }
    }

    // If we found explicit counts, use those
    if (testsRun > 0) {
      result.tests_run = testsRun;
      result.tests_passed = testsPassed || (testsRun - testsFailed);
      result.tests_failed = testsFailed;
    } else {
      // Fallback: assume one test per suite if no parsing worked
      result.tests_run = 1;
      result.tests_passed = stderr ? 0 : 1;
      result.tests_failed = stderr ? 1 : 0;
    }
  }

  /**
   * Collect test artifacts and reports
   */
  async collectArtifacts(suite, result) {
    const artifactDirs = [
      path.join(__dirname, suite.path),
      path.join(__dirname, 'reports'),
      projectRoot
    ];

    const artifactPatterns = [
      `*${suite.name}*report*.json`,
      `*${suite.name}*report*.md`,
      `*${suite.name}*results*.json`,
      '*coverage*',
      'test-*.html'
    ];

    for (const dir of artifactDirs) {
      for (const pattern of artifactPatterns) {
        try {
          const { stdout } = await execAsync(`find ${dir} -name "${pattern}" -type f 2>/dev/null || true`);
          const files = stdout.trim().split('\n').filter(Boolean);
          
          for (const file of files) {
            if (existsSync(file)) {
              const artifactName = path.basename(file);
              const targetPath = path.join(__dirname, 'artifacts', `${suite.name}-${artifactName}`);
              
              try {
                await fs.copyFile(file, targetPath);
                result.artifacts.push({
                  name: artifactName,
                  path: targetPath,
                  size: (await fs.stat(file)).size
                });
              } catch (error) {
                // Ignore copy errors
              }
            }
          }
        } catch (error) {
          // Ignore find errors
        }
      }
    }
  }

  /**
   * Calculate production readiness metrics
   */
  calculateReadinessScore() {
    let totalScore = 0;
    let maxScore = 0;
    let criticalFailures = 0;

    // Calculate weighted scores for each test suite
    for (const [suiteName, result] of Object.entries(this.results.testSuites)) {
      const suite = this.testSuites.find(s => s.name === suiteName);
      if (!suite) continue;

      maxScore += suite.weight * 100;
      
      if (result.status === 'completed') {
        totalScore += (result.success_rate || 0) * suite.weight;
      } else if (result.status === 'failed' && suite.critical) {
        criticalFailures++;
      }
    }

    // Calculate overall metrics
    const overallSuccessRate = maxScore > 0 ? (totalScore / maxScore * 100) : 0;
    let readinessScore = overallSuccessRate;

    // Apply penalties
    if (criticalFailures > 0) {
      readinessScore -= (criticalFailures * 15); // 15 point penalty per critical failure
    }

    // Ensure score is between 0-100
    readinessScore = Math.max(0, Math.min(100, readinessScore));

    // Determine production readiness
    const productionReady = readinessScore >= 85 && criticalFailures === 0;

    return {
      overall_success_rate: overallSuccessRate,
      readiness_score: readinessScore,
      production_ready: productionReady,
      critical_failures: criticalFailures,
      grade: this.calculateGrade(readinessScore)
    };
  }

  /**
   * Calculate letter grade based on readiness score
   */
  calculateGrade(score) {
    if (score >= 97) return 'A+';
    if (score >= 93) return 'A';
    if (score >= 90) return 'A-';
    if (score >= 87) return 'B+';
    if (score >= 83) return 'B';
    if (score >= 80) return 'B-';
    if (score >= 77) return 'C+';
    if (score >= 73) return 'C';
    if (score >= 70) return 'C-';
    if (score >= 67) return 'D+';
    if (score >= 60) return 'D';
    return 'F';
  }

  /**
   * Generate comprehensive JSON report
   */
  async generateJSONReport() {
    const totalDuration = this.getDeterministicTimestamp() - this.startTime;
    
    // Calculate final metrics
    const readinessMetrics = this.calculateReadinessScore();
    
    // Update summary
    this.results.summary = {
      ...this.results.summary,
      ...readinessMetrics,
      total_duration: totalDuration
    };

    // Count totals across all suites
    for (const result of Object.values(this.results.testSuites)) {
      this.results.summary.total_tests += result.tests_run;
      this.results.summary.total_passed += result.tests_passed;
      this.results.summary.total_failed += result.tests_failed;
      this.results.summary.total_skipped += result.tests_skipped;
    }

    const reportData = {
      meta: {
        report_type: 'master_test_orchestration',
        generated_at: this.getDeterministicDate().toISOString(),
        orchestrator_version: '1.0.0',
        total_duration_ms: totalDuration
      },
      ...this.results
    };

    const reportPath = path.join(__dirname, 'reports', 'master-test-report.json');
    await fs.writeFile(reportPath, JSON.stringify(reportData, null, 2));
    
    return reportData;
  }

  /**
   * Generate HTML report
   */
  async generateHTMLReport(reportData) {
    const html = `<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unjucks Master Test Report</title>
    <style>
        body { 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 0; padding: 20px; background: #f5f5f5; line-height: 1.6;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        .header { background: #2563eb; color: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; }
        .grade { font-size: 2em; font-weight: bold; }
        .grade.A, .grade.A- { color: #10b981; }
        .grade.B { color: #f59e0b; }
        .grade.C, .grade.D { color: #ef4444; }
        .grade.F { color: #dc2626; }
        .card { background: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .metric { display: inline-block; margin: 10px; padding: 15px; background: #f1f5f9; border-radius: 6px; }
        .test-suite { border-left: 4px solid #10b981; }
        .test-suite.failed { border-left-color: #ef4444; }
        .test-suite.critical { border-left-color: #dc2626; }
        .progress-bar { width: 100%; height: 20px; background: #e5e7eb; border-radius: 10px; overflow: hidden; }
        .progress { height: 100%; background: #10b981; transition: width 0.3s; }
        .progress.failed { background: #ef4444; }
        table { width: 100%; border-collapse: collapse; margin: 20px 0; }
        th, td { padding: 12px; text-align: left; border-bottom: 1px solid #e5e7eb; }
        th { background: #f8fafc; font-weight: 600; }
        .status-passed { color: #10b981; font-weight: bold; }
        .status-failed { color: #ef4444; font-weight: bold; }
        .status-skipped { color: #6b7280; }
        .production-ready { background: #10b981; color: white; padding: 10px; border-radius: 6px; display: inline-block; }
        .not-production-ready { background: #ef4444; color: white; padding: 10px; border-radius: 6px; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üß™ Unjucks Master Test Report</h1>
            <div class="grade grade-${reportData.summary.grade.replace('+', '-plus').replace('-', '-minus')}">${reportData.summary.grade}</div>
            <p><strong>Production Ready:</strong> 
                <span class="${reportData.summary.production_ready ? 'production-ready' : 'not-production-ready'}">
                    ${reportData.summary.production_ready ? '‚úÖ YES' : '‚ùå NO'}
                </span>
            </p>
            <p>Generated: ${reportData.meta.generated_at}</p>
        </div>

        <div class="card">
            <h2>üìä Executive Summary</h2>
            <div class="metric">
                <h3>Overall Readiness Score</h3>
                <div style="font-size: 2em; font-weight: bold; color: #2563eb;">
                    ${reportData.summary.readiness_score.toFixed(1)}%
                </div>
            </div>
            <div class="metric">
                <h3>Test Success Rate</h3>
                <div style="font-size: 1.5em; color: #10b981;">
                    ${reportData.summary.overall_success_rate.toFixed(1)}%
                </div>
            </div>
            <div class="metric">
                <h3>Total Tests</h3>
                <div>${reportData.summary.total_tests}</div>
            </div>
            <div class="metric">
                <h3>Critical Failures</h3>
                <div style="color: ${reportData.summary.critical_failures > 0 ? '#ef4444' : '#10b981'};">
                    ${reportData.summary.critical_failures}
                </div>
            </div>
        </div>

        <div class="card">
            <h2>üß™ Test Suite Results</h2>
            <table>
                <thead>
                    <tr>
                        <th>Suite</th>
                        <th>Status</th>
                        <th>Tests</th>
                        <th>Success Rate</th>
                        <th>Duration</th>
                        <th>Critical</th>
                    </tr>
                </thead>
                <tbody>
                    ${Object.values(reportData.testSuites).map(suite => `
                        <tr class="test-suite ${suite.status === 'failed' ? 'failed' : ''} ${suite.critical ? 'critical' : ''}">
                            <td><strong>${suite.name}</strong><br><small>${suite.description}</small></td>
                            <td class="status-${suite.status}">${suite.status.toUpperCase()}</td>
                            <td>${suite.tests_passed}/${suite.tests_run} 
                                ${suite.tests_failed > 0 ? `(${suite.tests_failed} failed)` : ''}
                            </td>
                            <td>
                                <div class="progress-bar">
                                    <div class="progress ${suite.success_rate < 80 ? 'failed' : ''}" 
                                         style="width: ${suite.success_rate || 0}%"></div>
                                </div>
                                ${(suite.success_rate || 0).toFixed(1)}%
                            </td>
                            <td>${(suite.duration / 1000).toFixed(1)}s</td>
                            <td>${suite.critical ? 'üî¥ Yes' : '‚ö™ No'}</td>
                        </tr>
                    `).join('')}
                </tbody>
            </table>
        </div>

        <div class="card">
            <h2>üîß Environment Information</h2>
            <table>
                <tr><td><strong>Node.js Version</strong></td><td>${reportData.environment.node_version}</td></tr>
                <tr><td><strong>Platform</strong></td><td>${reportData.environment.platform} ${reportData.environment.arch}</td></tr>
                <tr><td><strong>CLI Version</strong></td><td>${reportData.environment.cli_version}</td></tr>
                <tr><td><strong>Package</strong></td><td>${reportData.environment.package_info.name} v${reportData.environment.package_info.version}</td></tr>
                <tr><td><strong>Total Duration</strong></td><td>${(reportData.meta.total_duration_ms / 1000).toFixed(2)} seconds</td></tr>
            </table>
        </div>

        <div class="card">
            <h2>üìà Recommendations</h2>
            ${reportData.summary.production_ready ? 
                '<p style="color: #10b981; font-weight: bold;">üéâ System is production ready! All critical tests passing.</p>' :
                `<div>
                    <h3 style="color: #ef4444;">‚ö†Ô∏è Issues to Address:</h3>
                    <ul>
                        ${reportData.summary.critical_failures > 0 ? 
                            '<li><strong>Critical:</strong> Fix failing critical test suites before production deployment</li>' : ''}
                        ${reportData.summary.readiness_score < 85 ? 
                            '<li><strong>Quality:</strong> Improve test coverage and fix failing tests to reach 85% readiness threshold</li>' : ''}
                        <li><strong>Monitoring:</strong> Set up continuous testing in CI/CD pipeline</li>
                        <li><strong>Documentation:</strong> Update documentation based on test results</li>
                    </ul>
                </div>`
            }
        </div>

        <footer style="text-align: center; padding: 20px; color: #6b7280;">
            Generated by Unjucks Master Test Orchestrator v1.0.0
        </footer>
    </div>
</body>
</html>`;

    const reportPath = path.join(__dirname, 'reports', 'master-test-report.html');
    await fs.writeFile(reportPath, html);
    
    return reportPath;
  }

  /**
   * Generate Markdown report
   */
  async generateMarkdownReport(reportData) {
    const md = `# üß™ Unjucks Master Test Report

**Generated:** ${reportData.meta.generated_at}  
**Duration:** ${(reportData.meta.total_duration_ms / 1000).toFixed(2)} seconds  
**CLI Version:** ${reportData.environment.cli_version}  
**Node.js:** ${reportData.environment.node_version}  
**Platform:** ${reportData.environment.platform}

## üéØ Executive Summary

### Production Readiness: ${reportData.summary.production_ready ? '‚úÖ **READY**' : '‚ùå **NOT READY**'}

| Metric | Value | Grade |
|--------|-------|-------|
| **Overall Readiness Score** | **${reportData.summary.readiness_score.toFixed(1)}%** | **${reportData.summary.grade}** |
| **Test Success Rate** | ${reportData.summary.overall_success_rate.toFixed(1)}% | |
| **Total Tests Executed** | ${reportData.summary.total_tests} | |
| **Tests Passed** | ${reportData.summary.total_passed} ‚úÖ | |
| **Tests Failed** | ${reportData.summary.total_failed} ‚ùå | |
| **Tests Skipped** | ${reportData.summary.total_skipped} ‚è≠Ô∏è | |
| **Critical Failures** | ${reportData.summary.critical_failures} | |

## üìä Test Suite Breakdown

${Object.values(reportData.testSuites).map(suite => `
### ${suite.critical ? 'üî¥' : '‚ö™'} ${suite.name.toUpperCase()} 
**${suite.description}**

- **Status:** ${suite.status === 'completed' ? '‚úÖ COMPLETED' : suite.status === 'failed' ? '‚ùå FAILED' : '‚è≥ ' + suite.status.toUpperCase()}
- **Tests Run:** ${suite.tests_run}
- **Passed:** ${suite.tests_passed} ‚úÖ
- **Failed:** ${suite.tests_failed} ‚ùå
- **Success Rate:** ${(suite.success_rate || 0).toFixed(1)}%
- **Duration:** ${(suite.duration / 1000).toFixed(2)}s
- **Weight:** ${(suite.weight * 100).toFixed(0)}% of total score
- **Critical:** ${suite.critical ? 'Yes - Blocks production deployment' : 'No'}

${suite.error ? `
**Error Details:**
\`\`\`
${suite.error}
\`\`\`
` : ''}

${suite.artifacts.length > 0 ? `
**Generated Artifacts:**
${suite.artifacts.map(artifact => `- ${artifact.name} (${(artifact.size / 1024).toFixed(1)} KB)`).join('\n')}
` : ''}
`).join('\n---\n')}

## üîß Environment Details

- **Package:** ${reportData.environment.package_info.name} v${reportData.environment.package_info.version}
- **Dependencies:** ${reportData.environment.package_info.dependencies} production, ${reportData.environment.package_info.devDependencies} dev
- **Memory Usage:** ${Math.round(reportData.environment.memory.heapUsed / 1024 / 1024)} MB heap used
- **Working Directory:** ${reportData.environment.cwd}

## üìà Analysis & Recommendations

${reportData.summary.production_ready ? `
### ‚úÖ Production Ready! 

üéâ **Congratulations!** Your system has achieved production readiness with a ${reportData.summary.grade} grade.

**Strengths:**
- All critical test suites passing
- High overall success rate (${reportData.summary.overall_success_rate.toFixed(1)}%)
- No critical failures detected
- Comprehensive test coverage across all major components

**Next Steps:**
- Deploy to production with confidence
- Set up continuous monitoring
- Maintain test coverage in CI/CD pipeline
` : `
### ‚ö†Ô∏è Not Production Ready

**Issues to Address Before Production:**

${reportData.summary.critical_failures > 0 ? `
#### üö® Critical Failures (${reportData.summary.critical_failures})
Critical test suites are failing. These MUST be fixed before production deployment.
` : ''}

${reportData.summary.readiness_score < 85 ? `
#### üìä Low Readiness Score (${reportData.summary.readiness_score.toFixed(1)}%)
Current score is below the 85% production readiness threshold.
` : ''}

**Action Items:**
1. **Immediate:** Fix all critical test failures
2. **High Priority:** Increase test success rate to >90%
3. **Medium Priority:** Add missing test coverage
4. **Low Priority:** Optimize performance and reduce test execution time

**Estimated Time to Production Ready:** 
${reportData.summary.critical_failures > 0 ? '1-3 days (critical fixes)' : 
  reportData.summary.readiness_score < 70 ? '3-5 days (major improvements)' : 
  '1-2 days (minor fixes)'}
`}

## üìã Test Coverage Analysis

${Object.entries(reportData.testSuites).map(([name, suite]) => {
  const coverage = suite.success_rate || 0;
  const status = coverage >= 90 ? 'üü¢ Excellent' : 
                coverage >= 80 ? 'üü° Good' : 
                coverage >= 60 ? 'üü† Fair' : 'üî¥ Poor';
  return `- **${name}**: ${coverage.toFixed(1)}% ${status}`;
}).join('\n')}

## üèÜ Quality Gates

| Gate | Requirement | Status |
|------|-------------|--------|
| **Critical Tests** | All passing | ${reportData.summary.critical_failures === 0 ? '‚úÖ PASS' : '‚ùå FAIL'} |
| **Overall Success** | ‚â•90% | ${reportData.summary.overall_success_rate >= 90 ? '‚úÖ PASS' : '‚ùå FAIL'} |
| **Readiness Score** | ‚â•85% | ${reportData.summary.readiness_score >= 85 ? '‚úÖ PASS' : '‚ùå FAIL'} |
| **Test Execution** | No crashes | ${Object.values(reportData.testSuites).every(s => s.status !== 'failed') ? '‚úÖ PASS' : '‚ùå FAIL'} |

## üìÅ Generated Reports & Artifacts

### Main Reports
- \`master-test-report.json\` - Detailed JSON data
- \`master-test-report.html\` - Interactive HTML report  
- \`master-test-report.md\` - This markdown summary

### Test Suite Artifacts
${Object.values(reportData.testSuites)
  .filter(suite => suite.artifacts.length > 0)
  .map(suite => `
#### ${suite.name}
${suite.artifacts.map(artifact => `- ${artifact.name}`).join('\n')}
`).join('')}

---

**Report Generated by:** Unjucks Master Test Orchestrator v1.0.0  
**Timestamp:** ${reportData.meta.generated_at}  
**Total Execution Time:** ${(reportData.meta.total_duration_ms / 1000).toFixed(2)} seconds
`;

    const reportPath = path.join(__dirname, 'reports', 'MASTER-TEST-REPORT.md');
    await fs.writeFile(reportPath, md);
    
    return reportPath;
  }

  /**
   * Run all tests and generate comprehensive reports
   */
  async runAllTests() {
    console.log('üéØ UNJUCKS MASTER TEST ORCHESTRATOR');
    console.log('===================================');
    console.log('Mission: Prove everything works and assess production readiness\n');

    try {
      // Setup clean environment
      await this.setupEnvironment();

      // Run each test suite
      console.log(`\nüìã Executing ${this.testSuites.length} test suites...\n`);
      
      for (const suite of this.testSuites) {
        await this.runTestSuite(suite);
      }

      // Generate comprehensive reports
      console.log('\nüìä Generating comprehensive reports...');
      
      const reportData = await this.generateJSONReport();
      const htmlPath = await this.generateHTMLReport(reportData);
      const mdPath = await this.generateMarkdownReport(reportData);

      // Print final summary
      console.log('\nüéâ MASTER TEST ORCHESTRATION COMPLETE!');
      console.log('======================================');
      
      console.log(`\nüèÜ FINAL SCORE: ${reportData.summary.grade} (${reportData.summary.readiness_score.toFixed(1)}%)`);
      
      if (reportData.summary.production_ready) {
        console.log('üü¢ STATUS: PRODUCTION READY ‚úÖ');
      } else {
        console.log('üî¥ STATUS: NOT PRODUCTION READY ‚ùå');
        console.log(`   Critical Failures: ${reportData.summary.critical_failures}`);
      }
      
      console.log(`\nüìà TEST RESULTS:`);
      console.log(`   Total Tests: ${reportData.summary.total_tests}`);
      console.log(`   Passed: ${reportData.summary.total_passed} ‚úÖ`);
      console.log(`   Failed: ${reportData.summary.total_failed} ‚ùå`);
      console.log(`   Skipped: ${reportData.summary.total_skipped} ‚è≠Ô∏è`);
      console.log(`   Success Rate: ${reportData.summary.overall_success_rate.toFixed(1)}%`);
      console.log(`   Duration: ${(reportData.meta.total_duration_ms / 1000).toFixed(2)}s`);

      console.log(`\nüìã REPORTS GENERATED:`);
      console.log(`   üìä JSON Report: ${path.join(__dirname, 'reports', 'master-test-report.json')}`);
      console.log(`   üåê HTML Report: ${htmlPath}`);
      console.log(`   üìù Markdown Report: ${mdPath}`);
      
      const artifactCount = Object.values(reportData.testSuites)
        .reduce((sum, suite) => sum + suite.artifacts.length, 0);
      
      if (artifactCount > 0) {
        console.log(`   üìÅ Test Artifacts: ${artifactCount} files in ${path.join(__dirname, 'artifacts')}`);
      }

      // Exit with appropriate code
      const exitCode = reportData.summary.production_ready ? 0 : 1;
      
      console.log(`\nüéØ RECOMMENDATION: ${reportData.summary.production_ready ? 
        'System is ready for production deployment!' : 
        'Address failing tests before production deployment.'}`);

      return {
        reportData,
        exitCode,
        paths: { html: htmlPath, markdown: mdPath }
      };

    } catch (error) {
      console.error('\n‚ùå ORCHESTRATION FAILED:', error);
      
      // Generate failure report
      const errorReport = {
        meta: {
          report_type: 'orchestration_failure',
          generated_at: this.getDeterministicDate().toISOString(),
          error: error.message
        },
        environment: this.results.environment,
        testSuites: this.results.testSuites,
        summary: {
          ...this.results.summary,
          production_ready: false,
          readiness_score: 0,
          grade: 'F'
        }
      };

      await fs.writeFile(
        path.join(__dirname, 'reports', 'orchestration-failure-report.json'), 
        JSON.stringify(errorReport, null, 2)
      );

      return { reportData: errorReport, exitCode: 2, error };
    }
  }
}

// Execute if called directly
if (import.meta.url === `file://${process.argv[1]}`) {
  const orchestrator = new MasterTestOrchestrator();
  
  orchestrator.runAllTests()
    .then(({ reportData, exitCode, error }) => {
      if (error) {
        console.error('Orchestration failed with error:', error.message);
      }
      process.exit(exitCode);
    })
    .catch(error => {
      console.error('Fatal orchestration error:', error);
      process.exit(2);
    });
}

export default MasterTestOrchestrator;